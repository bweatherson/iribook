In the previous section we argued that for rational agents, conditionalising on something they believe doesn't change the correct answer to any inquiry. And what's true for rational agents is, as usual in a functionalist story, part of the functional role that individuates mental states. So what it is for an agent to believe that \(p\) is, in part, for the agent to not change their mind when they conditionalise on \(p\). As we'll see presently, this looks much too strong. For just about any proposition, there's \textit{some} question whose answer looks different when you conditionalise on that proposition. So it looks like we believe very little. That, I think, would be a mistaken conclusion. The better way forward is to restrict the quantifier `any question'. What's really true is that if a rational agent believes \(p\), then conditionalising on \(p\) doesn't change the answer to any \textit{relevant} question, where what is relevant depends on their interests.

This, I propose, is a key way in which beliefs are interest-relative. What we believe is in part a function of what we care about. In \cite{Weatherson2005-WEACWD} I argued that this explains \textit{all} the interest-relativity we find in epistemology. For reasons I'll get to later in the chapter, I no longer believe that. But I do believe it explains a lot of the interest-relativity. I'm somewhat confident that it explains all the interest-relativity that has been hitherto uncovererd in the literature, for example. But before we get to that conclusion, let's step back to see why interests need to come in.

Beliefs structure inquiry and planning. If you believe \(p\), then \(p\) is a fixed point, a given, around which you plan. There is perhaps a more casual sense of `believe' in which this isn't true. If Smith says, ``I believe I turned the gas off, but I better go back and check,'' then Smith does \textit{not} believe, in the sense we're using here, that she turned the gas off. If she did believe that, there wouldn't be any need to go back and check, since she would have settled to her own satisfaction the question of whether the gas was turned off. The sense of `believe' I'm using here, where to believe something is to take it to be settled, is I think the common philosophical usage in epistemology and philosophy of mind. When we talk about the conditions necessary for a belief to be justified, we don't mean to talk about what would justify an agent being as confident in a proposition as Smith is that she turned the gas off. We mean to be aiming for something stronger. Or consider what we mean when we say that an agent who wants \(\phi\), and believes that doing \(\psi\) is the best way to get \(\phi\), should indeed do \(\psi\). We don't mean that if the agent is kinda confident that doing \(\psi\) is the best way to get \(\phi\), she should do \(\psi\). Rather, we mean that if the agent has settled to their own satisfaction that doing \(\psi\) is the best way to get \(\phi\), then \(\psi\) is what they should do. On this point, I'm going to follow standard philosophical usage throughout this work.\footnote{There is some interesting discussion in \cite[??]{FantlMcGrath2009} on the relationship between the casual and the philosophical usages.}

What we take as given in inquiry varies as the subject of inquiry varies. The easiest way to see this is by thinking of the examples John Hawthorne presents at the start of \citeauthor{Hawthorne2004} \textit{Knowledge and Lotteries}. Imagine first that I'm inquiring about what I'll be teaching next Fall, where I know this is information that is accessible to me.\footnote{The inquiry might just involve racking my brains for the relevant memory. When I talk about inquiries, I don't mean anything nearly as formal as a judicial inquest, or even something that need take more than a few seconds.} In such an inquiry, I'll simply assume that I won't be dead by next Fall, or have been fired, or that my school will have folded for financial reasons. Rather, I'll just focus on what I know about the teaching schedule. Now imagine that I'm deciding whether to buy either life insurance or unemployment insurance, so I'm trying to figure out the likelihood that such a policy will pay out. In that inquiry, I clearly won't assume that I'll be alive and teaching in a year's time. Indeed, the point of the inquiry is to figure out whether just those propositions, the ones I had previously taken as given, are actually true. Note the claim here is descriptive, not normative. I'm not saying yet that I should take different things as given in different inquiries. I happen to believe that, but I'm not arguing yet. All I'm relying on so far is the observation that I do make different presuppositions in different inquiries, and I assume that you do too.

The last two paragraphs suggest an argument that we believe very little. If a belief should be presupposed in any inquiry, and very little is presupposed in all inquiries, then we believe very little. We can put the same point in the terms used in the previous section. For almost any proposition \(p\), there is some inquiry where conditionalising on \(p\) changes the answer. Most obviously, there is the inquiry into the probability of \(p\). Since the conditional probability of \(p\) given \(p\) is 1, conditionalising on \(p\) will change the answer to the question \textit{What is the probability of p?} unless the answer to that question was already 1. So only propositions whose probability is 1 are believed. But that's not even a sufficient condition for belief. We might also be interested in what the conditional probability is of \(p\) given \(\neg p \vee q\), where \(q\) is some absurdity. Even if we think the probability of \(p\) is 1, we might think the conditional probability of \(p\) given \(\neg p \vee q\) is less than 1. (That is, if we're either wrong about \(p\), or wrong about \(\neg q\), we might think it at least possible that we're wrong about \(\neg q\).) But the conditional probability of \(p\) given \(p \wedge (\neg p \vee q)\) is, of course, 1. So if conditionalising on \(p\) does not change the answer to \textit{any} question, it must be that for any \(q\), the probability of \(p\) given \(\neg p \vee q\) is 1, for just about any \(q\).\footnote{There are technical issues that arise here if \(q\) is an impossibility. I mean to simply side-step those issues, which is why the weaselly phrase `just about' is there.} And very few propositions, outside perhaps of basic arithmetical truths, satisfy that condition.

A natural thought here would be that the model of the previous section is wrong. After all, we believe a lot, but we've just seen an argument that given that model, we believe very little. So, we might well conclusion, the model must be wrong. That's not what I'm going to conclude, however. I'm going to conclude that the model has been misapplied, and that the correct application takes us to the truth.

Let's focus again on the platitudes about belief we developed. Beliefs structure inquiry. Different inquiries have different structures. A natural inference to draw from these platitudes is that we believe different things when engaged in different inquiries. And we can put this into the formal model. We said that to believe \(p\) it must be that conditionalising on \(p\) does not change the answer to any question. We should have qualified that by saying that the question must be one that's relevant to your current inquiries. You can believe \(p\), even though you wouldn't take \(p\) as given in a different inquiry. All that qualification shows is that if you were engaged in a different inquiry, you wouldn't believe \(p\). Since you're not engaged in that inquiry, it's possible you do believe \(p\).

It's time to say a little bit more about what it is to be engaged in an inquiry. I'm not going to offer a short snappy answer to this question, but I will fill in some key details. We'll start with practical inquiries, in particular inquiries about whether to do \(\phi\) or \(\psi\), where these are actions. An action \(\phi\) is a live option for the agent if it is really possible for the agent to perform \(\phi\). An action \(\phi\) is a salient option if it is an option the agent takes seriously in deliberation. Most of the time gambling large sums of money on internet gambling sites over my phone is a live option, but not a salient option. I know this option is suboptimal, and I don't have to recompute every time whether I should do it. Whenever I'm making a decision, I don't have to add in to the list of choices \textit{bet thousands of dollars on internet gambling sites}, and then rerule that out every time. I just don't consider that option, and for what it's worth, I'm right do so. If I have a propensity to daydream, then it might be that becoming the centrefielder for the Boston Red Sox is a salient option to me, but it certainly isn't a live option. Whenever \(\phi\) and \(\psi\) are live and salient options for the agent, the question of which of them to do is part of her inquiries. So if she believes \(p\), and \(\phi\) and \(\psi\) are live, salient options, her preference ranking over them must equal her preference ranking over them given \(p\).

An agent need not only make decisions about what to do; she might also decide what to do conditional on some hypothesis or other. We need to factor this into our definition of an inquiry. Say a proposition is \textit{relevant} if the agent is disposed to take seriously the question of whether it is true (whether or not she is currently considering that question) and conditionalising on that proposition or its negation changes some of the agents \textit{unconditional} preferences over live, salient options.\footnote{Conditionalising on the proposition \textit{There are space aliens about to come down and kill all the people writing epistemology books} will make me prefer to stop writing this paper, and perhaps grab some old metaphysics papers I could be working on. So that proposition satisfies the second clause of the definition of relevance. But it clearly doesn't satisfy the first clause, so it's not relevant.} The first clause is designed to rule out wild hypotheses that the agent does not take at all seriously. If \(q\) is not such a proposition, if the agent is disposed to take it seriously, then it is relevant if there are live, salient \(\phi\) and \(\psi\) such that \(\phi \geq _q \psi \leftrightarrow  \phi \geq \psi\) is false. Say a proposition is \textit{salient} if the agent is currently considering whether it is true. Finally, say a proposition is \textit{active} relative to \(p\) iff it is a (possibly degenerate) conjunction of propositions such that each conjunct is either relevant or salient, and such that the conjunction is consistent with \(p\). (By a degenerate conjunction I mean a conjunction with just one conjunct. The consistency requirement is there because it might be hard in some cases to make sense of preferences given inconsistencies.) Then if \(q\) is active, and \(phi\) and \(psi\) are live and salient, the question of whether \(\phi\) or \(psi\) is better given \(q\) is part of the agent's inquiry. So the agent only believes \(p\) if \(\phi \geq _q \psi \leftrightarrow \phi \geq _{p \wedge q} \psi\).

Not all inquiries are practical inquiries. Most of the inquiries that this book concerns are not, for example. These theoretical inquiries also affect what is relevant to the agent. One of the shortcomings of previous work on interest-relativity in epistemology is that the various author's haven't spent as much time as they should on \textit{theoretical} interests of inquirers. Let's say a bit about those.

Some inquiries are inquiries into the truth of some proposition. When the agent is making such an inquiry, she doesn't take the answer as given. So when the question \textit{Is it true that p?} is a live question for the agent, she doesn't believe that \(p\) until that question is answered to her satisfaction. Our model captures this in a somewhat roundabout way. Since the question \textit{p?} is live, but the question \textit{Given p, p?} is not live (assuming minimal rationality), the agent has different attitudes to a question, namely \textit{p?}, depending on whether or not we conditionalise on \(p\). So she doesn't believe \(p\).

It's more interesting to think about inquiries into the probability of some proposition. We can ask all sorts of questions about the probability of various propositions. In some cases we might be interested in these questions for practical reasons, such as when we are deciding whether to buy some kind of insurance. But in other cases we care about them simply out of curiosity, such as when we wonder about the probability of human life persisting for another 10,000 years. In these cases, a question is relevant to the agent simply if she makes it relevant by thinking about it.

But we should be careful about just what kind of probabilistic questions agents ask. It's actually somewhat uncommon to be concerned with the \textit{exact} value of some probability. It's much more usual to be concerned with whether a probability falls in some interval, or whether one of two propositions is more probable than another. We might ask the question about intervals directly, as in \textit{Is the probability of p greater than 0.95?}. Or we might ask it somewhat indirectly, as when we ask what the probability of \(p\) is, but we really only care about the first two significant figures. In either of these cases, a bit surprisingly, it is possible to believe that \(p\) even though the probability of \(p\) is less than 1. That's because whether the probability of \(p\) falls into a relevant interval doesn't change when we conditionalise on \(p\). That's true in the first case (\textit{Is the probability of p greater than 0.95?}) as long as \(p\)'s unconditional probability is greater than 0.95, and in the second case (\textit{What's the probability of p to two significant figures?}) as long as the probability of \(p\) is greater than 0.995. So even raising probabilistic questions about \(p\) isn't, strictly speaking, incompatible with believing \(p\) when \(p\) isn't absolutely certain.\footnote{There's a surprising asymmetry around here. If we ask what the probability of \(\neg p\) is to some number of significant figures, the answer to that question will be different depending on whether we conditionalise on \(p\) unless the unconditional probability of \(p\) is 1. In some ways, that's the more natural case. It's a little unnatural to take \(p\) as given in an inquiry into the probability of \(p\), and it's a little surprising that our model allows this.}

Let's sum all this up. A key part of the functional role of belief is that beliefs structure inquiry. But how an agent structures inquiry depends on what they're inquiring into. I draw the obvious conclusion that what an agent believes depends on what they're inquiring into. We might be able to turn all this into a reductive analysis. The `structuring' role of belief captures a lot of the internal role of belief, and belief's role in generating action. It doesn't cover the `input' conditions for belief. But the input conditions for belief, that beliefs are based in evidence, are the same as the input conditions for credences. So the following account of belief arguably captures all the functional roles of belief.

\begin{quote}
\(S\) believes that \(p\) iff for any inquiry \(S\) is engaged in, \(S\)'s credence in \(p\) is high enough that conditionalising on \(p\) will not change the answer she gives to that inquiry.
\end{quote}