Both of the objections I'm going to make to the Threshold View are found in a short passage by Robert Stalnaker \citeyearpar[91]{Stalnaker1984}. Neither objection seems to have been particularly convincing to the wider world, since the Threshold View retains, and even gains, adherents. So I'll spend some time saying why each of them are good objections.

The Threshold View says that  \(S\) believes that \(p\) iff \(S\)'s credence in \(p\) is greater than some salient number \(r\), where \(r\) is made salient either by the context of belief ascription, or the context that \(S\) is in. As Stalnaker emphasises, any number \(r\) is bound to seem arbitrary. Unless these numbers are made salient by the environment, there is no special difference between believing \(p\) to degree 0.9786 and believing it to degree 0.9875. But if \(r\) is 0.98755, this will be \textit{the difference} between believing \(p\) and not believing it. Intuitively, that difference \textit{is} an important difference, so it can't simply be the difference between believing \(p\) to degree 0.9786 and believing it to degree 0.9875.

The usual response to Stalnaker, as found in \citet[Ch. 4]{Foley1993} and \cite{Hunter1996} is to say that the boundary is vague. But when we consider in more detail how vagueness is supposed to help here, this response doesn't seem successful. That's because on many different theories of vagueness, whatever is true on any way of making the vague term precise is still true. Or, at the very least, anything that isn't expressly about the vagueness of the term and is true on all precisifications is also true. And we have good reasons to think that some such theory of vagueness must be true.

If epistemicism about vagueness, as defended by for example Timothy \cite{Williamson1994-WILV}, is correct, then Foley and Hunter's position seems untenable. If epistemicism is correct, then every vague term picks out a boundary that is metaphysically precise, but unknowable. But the problem with the arbitrariness of \(r\) is not solved by noting that we can't know where \(r\) is. The same kind of conclusion will follow on any theory of vagueness where boundaries are metaphysically sharp, such as the contextualism defended by Delia Graff \cite{Fara2000}.

If a traditional degree of truth theory, as defended by for example Kenton \cite{Machina1976} is correct, this objection won't go through. After all, it isn't true on such a theory that anything that's true on any precisification is simply true. For example, the claim that \(S\) doesn't both believe and not believe \(p\) isn't true on the degree of truth theory if it's true to degree 0.5 that \(S\) believes that \(p\). But this leads to two new problems. One technical problem is that it isn't clear this is still the Threshold View, since it isn't true that there's a threshold.\footnote{That is, the existentially quantified claim \(\exists r \forall S \forall p (S \) believes that \(p\) iff \(S\)'s credence in \(p\) is greater than \(r)\) will have a very low degree of truth. That is because on these degree of truth theories, the truth value of an existentially quantified claim is the maximum of the truth value of the various instances of that claim, and no instance of this claim will be more than minimally true.} But I won't stress this, since the view is obviously in the spirit of the Threshold View. The bigger problem, as pointed out by Timothy Williamson \citeyearpar[Ch. 4]{Williamson1994-WILV} is that it is very implausible that these negated conjunctions are not true. Nothing in the nature of vagueness, argues Williamson, gives us reason to deny that contradictions are always false. Modern degree of truth theories, such as the theory I defend in \cite{Weatherson2005-WEATTT}, agree with Williamson that all contradictions should be false. But these theories also agree with epistemicism that what's true on all precisifications is really true.

A little surprisingly, the theory of vagueness that looks most promising for the Threshold View is supervaluationism. This is surprising because you might think that the core premise of my objection, that what is true on any precisification is simply true, is the defining characteristic of supervaluationism. But matters turn out to be a little more delicate than that. After all, supervaluationists have learned to say that some things that are true on all precisifications aren't necessarily true.\footnote{I think the best discussion of this point is still \cite{Lewis1993c}.} For instance, it's plausibly true on all precisifications that `bald' is precise. It doesn't follow that it's really true that `bald' is precise. So meta-linguistic claims that are true on all precisifications need not be true.

If we were being clumsy with the objection to the Threshold View, it might seem like it turns on a metalinguistic claim. The clumsy way of stating the objection would be to say that it's implausible that the difference between things that satisfy `believes' and things that don't is arbitrary. If that were the objection, supervaluationism could offer a way out. That's because it's possible to imagine a combination of the Threshold View and supervaluationism which says that although it's true on every precisification that `believes' denotes an arbitrary boundary, it isn't actually true that `believes' denotes an arbitrary boundary.

The way around this problem is to note that we can state the objection without \textit{mentioning} any of the key terms. The core intuition is that the difference between having and not having a belief is, in general, a more psychologically significant distinction than any particular difference between nearby credences. That intuition uses terms like `belief' and `credence', it doesn't mention them. So if it's false, according to the Threshold View, on every precisification, then it is simply false on the Threshold View. And that's an unacceptable result.

We don't need to simply appeal to the popularity of these theories of vagueness to argue against the Threshold View here. It's independently plausible that the correct theory of vagueness should respect the principle that whatever's true on all precisifications is true. A little noticed reason for accepting this claim is that it plays a key role in certain parts of social science. I can illustrate this with an example from one of the most discussed academic books of the last hundred years, John Maynard Keynes's \textit{The General Theory of Employment, Interest and Money} \cite{Keynes1936}. 

The following five claims are all defended in the \textit{General Theory}, the first two on page 61, and the latter 3 on pages 225-6.

\begin{enumerate*}
\renewcommand{\labelenumi}{(\arabic{enumi})}
\item All goods are (definitely) investment goods or consumption goods.
\item For some goods it is vague whether they are an investment or consumption good. 
\item The yield of an investment, \(q\), is vague.
\item The carrying cost of an investment, \(c\), is vague.
\item The net yield of an investment, \(q - c\), can be precisely determined. 
\end{enumerate*}

\noindent Since Keynes endorsed these claims, he also endorsed, at least tacitly, their consistency. The \textit{General Theory} has been one of the most closely studied, and carefully critiqued, books of our time. And, to the best of my knowledge, the assumptions that these claims were consistent has not been criticised.\footnote{Not even in books like \cite{Coates1996} that are explicitly about the role of vagueness in the \textit{General Theory}.} 

This is a problem for theories of vagueness that do not allow that these claims are consistent. On Machina's theory, (1) and (2) are not consistent, since a disjunction like (1) can only be definitely true if one disjunct is definitely true, and (2) denies that either disjunct in (1) is definitely true. So some philosophers (though apparently no economists) disagree with Keynes on the consistency of (1) through (5). Since so many economists have accepted the consistency of these claims, we can safely say that it is intuitive that they are consistent. So a theory of vagueness that takes learned intuitions to be evidentially significant should agree that the claims are consistent. Moreover, the fact that things like net yields can be precise even though their components (gross yields and carrying costs) are vague plays a crucial role in Keynes's theory, and hence in \(20^{th}\) century economics. So a theory of vagueness that takes embedding in a flourishing science to be evidentially significant should agree that these claims are consistent. I'm inclined to think both that intuitions about vagueness are useful evidence, and that embedding in a flourishing science is useful evidence, so I think considering things like consumption goods and net yields gives us very good evidence against theories that deny the consistency of (1) through (5).

And note that it's not just that Keynes says that (1) through (5) are consistent. Both on page 61 and again on pages 225-6, he says that the reason he takes them to be consistent is that he thinks we should take to be true whatever turns out to be true on any arbitrary way of precisifying a vague boundary. So these passages, and their acceptance by a wide swathe of economists with widely differing views on the broader Keynesian program, provide strong evidence that whatever is true on any way of precisifying a vague boundary is simply true.

All of this is to say that if there's a problem with thresholds being arbitrary, making the thresholds vague seems to be of no help at all. Indeed, it's arguable that the vagueness of the threshold makes it even more arbitrary in some respects. The lesson of these examples from economics is that we don't go wrong by treating vague distinctions as arbitrary distinctions. So perhaps the defender of the Threshold View should deny that there's a problem with the distinction between belief and non-belief being arbitrary.

We can see that this position is unsustainable by thinking again about the role of belief in leading to action. Let's recall just what the Threshold View has to say about the decisions that will be reached in a case like \textit{Bad Roulette}. Recall that \(S\) receives an offer that has a clearly negative expected utility, but which has a very high probability of having a small positive return. Since \(S\)'s credence that the ticket will lose is high, according to the Threshold View, she believes her ticket will lose. So she believes that taking the offer will produce the best outcome. And she only cares about getting the best outcome, at least among the available choices. But she is not at all motivated to take the offer. This is, at the very least, rather strange.

And I think the strangeness is grounded in the arbitrariness of the Threshold. The difference between believing \(p\) and not believing \(p\) makes a difference to action. Among other things, it means that raising the probability of \(p\) does not, on its own, make betting on \(p\) more attractive. If you already believe \(p\), getting more evidence for \(p\) does not give you more reason to bet on \(p\).\footnote{This is related to the principle that \cite{FantlMcGrath2009} call `Safe Reasons', though I'm making a claim here about motivating reasons, not justificatory reasons.} Now if we abstract from the agent's situation, it's very hard to see why having a credence cross any threshold (short of 1) should mean that no more evidence matters to \(p\)-related decisions. For one thing, it could be that the agent faces a bet on \(p\) at astronomical odds, and hence with negative expected utility. But just as importantly, the relation between increased credence and action is continuous. The higher the credence in \(p\), the more bets on \(p\) you're prepared to accept. And a marginal increase in the credence of \(p\) means a marginal increase in the set of bets on \(p\) you're prepared to accept. There aren't any `jumps' in the function between credence and betting behaviour. The fact that beliefs have a distinctive role in motivating action suggests that the crossing boundary between belief and non-belief should make a significant, or at least a distinctive, difference in actions or dispositions to act. But increasing credence from 0.9785 to 0.9786, or whatever takes you across the threshold, does not make a significant difference.

The Interest-Relative Theory of belief does not face a problem here. Coming to believe that \(p\) does have a significant, and distinctive, effect. It means that you're prepared to accept all bets on \(p\) that you actually face. The Threshold View implies that there aren't any such nice generalisations about the role of belief in motivating action. That is a serious cost of the view.






%On an epistemic theory of vagueness, there is still a number such that degrees of belief above that count, and degrees below that do not, and any such number is bound to seem unimportant. On supervaluational theories, the same is true. There won't be a \textit{determinate} number, to be sure, but there will a number, and that seems false. My preferred degree of belief theory of vagueness, as set out in \cite{Weatherson2005-WEATTT} has the same consequence. Hunter defends a version of the threshold view combined with a theory of vagueness based around fuzzy logic, which seems to be the only theory that could avoid the arbitrariness objection. But as \cite{Williamson1994-WILV} showed, there are deep and probably insurmountable difficulties with that position. So I think the vagueness response to the arbitrariness objection is (a) the only prima facie plausible response and (b) unsuccessful. 

