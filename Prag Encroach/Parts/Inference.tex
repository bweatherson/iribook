So far I've argued that the Threshold View is committed to denials of multi-premise closure. I've also argued that this is is a very bad feature of the Threshold View, unless it is an unavoidable cost. And I've argued against thinking that the preface paradox provides a reason to resist that argument. But perhaps it is unavoidable. Perhaps, that is, any plausible theory about the relationship between belief and credence will imply that we have to give up on the intuitive multi-premise closure principle. The aim of this section is to show that that's not true. First, I'll argue that we get a reasonably strong closure principle from the Interest Relative Theory of belief. Second, I'll argue that the closure principle we get, although perhaps not as strong as what some theorists want, is as strong a principle as can be justified by arguments for closure.

Here's what we can prove from the Interest Relative Theory of Belief.

\begin{description*}
\item[Salient Closure:] Whenever \(p\) and \(q\) and their conjunction are all open or salient, and both are believed, and the agent is probabilistically coherent, the agent also believes \(p \wedge q\). 
\end{description*}

\noindent \textbf{Salient Closure} is not as strong a principle as some would like, since it is restricted to salient (or open) propositions. But the fact that it is weak isn't a reason to think it is \textit{false}. Indeed, its weakness is a reason to think it might just be true, even if stronger closure principles fail.

The proof of \textbf{Salient Closure} is a little complicated, but worth working through. First we'll prove that if the agent believes \(p\), believes \(q\), and \(p\) and \(q\) are both salient, then the agent prefers believing \(p \wedge q\) to not believing it, if \(p \wedge q\) is eligible for belief. In what follows \textit{Pr}(\(x | y\)) is the agent's conditional degree of belief in \(x\) given \(y\). Since the agent is coherent, we'll assume this is a probability function (hence the name).

\begin{enumerate*}
\item Since the agent believes that \(q\), they prefer believing that \(q\) to not believing that \(q\) (by the criteria for belief)
\item So, given \(p\), the agent prefers believing that \(q\) to not believing that \(q\). (From 1 and the fact that they believe that \(p\), and that \(q\) is salient)
\item So \textit{Pr}(\(q | p) > \nicefrac{1}{2}\) (from 2)
\item \textit{Pr}(\(q | p\)) = \textit{Pr}(\(p \wedge q | p\)) (by probability calculus)
\item So \textit{Pr}(\(p \wedge q | p\)) \(> \nicefrac{1}{2}\) (from 3, 4)
\item So, if \(p \wedge q\) is eligible for belief, then the agent prefers believing that \(p \wedge q\) to not believing it, given \(p\) (from 5)
\item So, if \(p \wedge q\) is eligible for belief, the agent prefers believing that \(p \wedge q\) to not believing it (from 6, and the fact that they believe that \(p\), and \(p \wedge q\) is salient)
\end{enumerate*}

\noindent So whenever, \(p, q\) and \(p \wedge q\) are salient, and the agent believes each conjunct, the agent prefers believing the conjunction \(p \wedge q\) to not believing it, if \(p \wedge q\) is eligible. Now we have to prove that \(p \wedge q\) is eligible for belief, to prove that it is actually believed. That is, we have to prove that (3) follows from (2) and (1), where the initial quantifiers range over actions that are open and salient \textit{tout court}.

\numbex{0}{
\item \(\forall\)A\(\forall\)B\(\forall r\) (A \(\geq_r\) B \(\leftrightarrow\) A \(\geq _p  \wedge r\) B)
\item \(\forall\)A\(\forall\)B\(\forall r\) (A \(\geq_r\) B \(\leftrightarrow\) A \(\geq _q  \wedge r\) B)
\item \(\forall\)A\(\forall\)B\(\forall r\) (A \(\geq_r\) B \(\leftrightarrow\) A \(\geq _{p \wedge q \wedge r}\) B)
}
\noindent Assume that (3) isn't true. That is, there are A, B and \(s\) such that \(\neg\)(A \(\geq_s\) B \(\leftrightarrow\) A \(\geq _{p \wedge q \wedge s}\)B). By hypothesis \(s\) is active, and consistent with \(p \wedge q\). So it is the conjunction of relevant, salient propositions. Since \(q\) is salient, this means \(q \wedge s\) is also active. Since \(s\) is consistent with \(p \wedge q\), it follows that \(q \wedge s\) is consistent with \(p\). So \(q \wedge s\) is a possible substitution instance for \(r\) in (1). Since (1) is true, it follows that A \(\geq _{q \wedge s}\) B \(\leftrightarrow\) A \(\geq _{p \wedge q \wedge s}\) B. By similar reasoning, it follows that \(s\) is a permissible substitution instance in (2), giving us A \(\geq_s\) B \(\leftrightarrow\) A \(\geq _{q \wedge s}\) B. Putting the last two biconditionals together we get A \(\geq_s\) B \(\leftrightarrow\) A \(\geq _{p \wedge q \wedge s}\)B, contradicting our hypothesis that there is a counterexample to (3). So whenever (1) and (2) are true, (3) is true as well, assuming \(p, q\) and \(p \wedge q\) are all salient.

So the Interest Relative Theory of belief does give us a closure principle, namely \textbf{Salient Closure}. But maybe we should not be happy with that. Some theorists will surely object that this isn't enough of a closure principle, since closure should not be restricted in this way. Here I want to defend the plausibility of the qualification. Let's start with what I take to be the most important argument for closure, the passage from Stalnaker's \textit{Inquiry} that I quoted above.

\begin{quote}
Reasoning in this way from accepted premises to their deductive consequences (\(P\), also \(Q\), therefore \(R\)) does seem perfectly straightforward. Someone may object to one of the premises, or to the validity of the argument, but one could not intelligibly agree that the premises are each acceptable and the argument valid, while objecting to the acceptability of the conclusion. \cite[92]{Stalnaker1984}
\end{quote}

\noindent Stalnaker's wording here is typically careful. The relevant question isn't whether we can accept \(p\), accept \(q\), accept \(p\) and \(q\) entail \(r\), and reject \(r\). As Christensen \citeyearpar[Ch. 4]{Christensen2005} notes, this is impossible even on the threshold view, as long as the threshold is above 2/3. The real question is whether we can accept \(p\), accept \(q\), accept \(p\) and \(q\) entail \(r\), and \textit{fail }to accept \(r\). And this is always a live possibility on any threshold view, though it seems absurd at first that this could be coherent.

But it's important to note how \textit{active} the verbs in Stalnaker's description are. When faced with a valid argument we have to \textit{object} to one of the premises, or the validity of the argument. What we can't do is \textit{agree} to the premises and the validity of the argument, while \textit{objecting} to the conclusion. I agree. If we are really \textit{agreeing} to some propositions, and \textit{objecting} to others, then all those propositions are salient. And in that case closure, deductive coherence, is mandatory. This doesn't tell us what we have to do if we haven't previously made the propositions salient in the first place.

The position I endorse here is very similar in its conclusions to that endorsed by Gilbert Harman in \textit{Change in View}. There Harman endorses the following principle. (At least he endorses it as true -- he doesn't seem to think it is particularly explanatory because it is a special case of a more general interesting principle.)

\begin{description*}
\item[Recognized Logical Implication Principle] One has reason to believe \(P\) if one \textit{recognizes} that \(P\) is logically implied by one's view. \cite[17]{Harman1986}
\end{description*}

\noindent This seems right to me, both what it says and its implicature that the reason in question is not a conclusive reason. My main objection to those who use the preface paradox to argue against closure is that they give us a mistaken picture of what we have \textit{to do} epistemically. When I have inconsistent beliefs, or I don't believe some consequence of my beliefs, that is something I have a reason to deal with at some stage, something I have to do. When we say that we have things to do, we don't mean that we have to do them \textit{right now}, or instead of everything else. My current list of things to do includes cleaning my bathroom, yet here I am writing this paper, and (given the relevant deadlines) rightly so. We can have the job of cleaning up our epistemic house as something to do while recognising that we can quite rightly do other things first. But it's a serious mistake to infer from the permissibility of doing other things that cleaning up our epistemic house (or our bathroom) isn't something to be done. The bathroom won't clean itself after all, and eventually this becomes a problem.

There is a possible complication when it comes to tasks that are very low priority. I used to own a house with a typically cluttered attic. I used to think that the attic could well be cleaned, or at least it could be cleaner, but there are no imaginable circumstances under which something else wouldn't be higher priority. Given that, should I really have \textit{clean the attic} on the list of things to be done? Similarly, there might be implications I haven't followed through that it couldn't possibly be worth my time to sort out. Are they things to be done? I think it's worthwhile recording them as such, because otherwise we might miss opportunities to deal with them in the process of doing something else. I don't need to put off anything else in order to clean the attic, but if I'm up there for independent reasons I should bring down some of the garbage. Similarly, I don't need to follow through implications mostly irrelevant to my interests, but if those propositions come up for independent reasons, I should deal with the fact that some things I believe imply something I don't believe. Having it be the case that all implications from things we believe to things we don't believe constitute jobs to do (possibly in the loose sense that cleaning my attic is something to do) has the right implications for what epistemic duties we do and don't have.\footnote{This example feels a little dated, since I wrote it when living in a spacious house up in Ithaca, not an apartment in Manhattan. But the thing about apartments is that you can't leave space in them poorly used for too long and not have it become a pressing job soon enough. No matter; it turns out that when you sell a house you don't sell the right to use it as a metaphor.}

While waxing metaphorical, it seems time to pull out a rather helpful metaphor that Gilbert \citeauthor{Ryle1949} develops in \textit{The Concept of Mind} at a point where he's covering what we'd now call the inference/implication distinction. (This is a large theme of chapter 9, see particularly pages 292-309.) Ryle's point in these passages, as it frequently is throughout the book, is to stress that minds are fundamentally active, and the activity of a mind cannot be easily recovered from its end state. Although Ryle doesn't use this language, his point is that we shouldn't confuse the difficult activity of drawing inferences with the smoothness and precision of a logical implication. The language Ryle does use is more picturesque. He compares the easy work a farmer does when sauntering down a path from the hard work he did when building the path. A good argument, in philosophy or mathematics or elsewhere, is like a well made path that permits sauntering from the start to finish without undue strain. But from that it doesn't follow that the task of coming up with that argument, of building that path in Ryle's metaphor, was easy work. The easiest paths to walk are often the hardest to build. Path-building, smoothing out our beliefs so they are consistent and closed under implication, is hard work, even when the finished results look clean and straightforward. Its work that we shouldn't do unless we need to. But making sure our beliefs are closed under entailment even with respect to irrelevant propositions is suspiciously like the activity of buildings paths between points without first checking you need to walk between them.

For a less metaphorical reason for doubting the wisdom of this unchecked commitment to closure, we might notice the difficulties theorists tend to get into all sorts of difficulties. Consider, for example, the view put forward by Mark \citeauthor{Kaplan1996} in \textit{Decision Theory as Philosophy}. Here is his definition of belief.

\begin{quote}
You count as believing P just if, were your sole aim to assert the truth (as it pertains to P), and you only options were to assert that P, assert that \(\neg\)P or make neither assertion, you would prefer to assert that P. (109)
\end{quote}

\noindent Kaplan notes that conditional definitions like this are prone to Shope's conditional fallacy. If my sole aim were to assert the truth, I might have different beliefs to what I now have. He addresses one version of this objection (namely that it appears to imply that everyone believes their sole desire is to assert the truth) but as we'll see presently he can't avoid all versions of it.

These arguments are making me thirsty. I'd like a beer. Or at least I think I would. But wait! On Kaplan's theory I can't think that I'd like a beer, for if my sole aim were to assert the truth as it pertains to my beer-desires, I wouldn't have beer desires. And then I'd prefer to assert that I wouldn't like a beer, I'd merely like to assert the truth as it pertains to my beer desires. 

Even bracketing this concern, Kaplan ends up being committed to the view that I can (coherently!) believe that \(p\) even while regarding \(p\) as highly improbable. This looks like a refutation of the view to me, but Kaplan accepts it with some equanimity. He has two primary reasons for saying we should live with this. First, he says that it only looks like an absurd consequence if we are committed to the Threshold View. To this all I can say is that \textit{I} don't believe the Threshold View, but it still seems absurd to me. Second, he says that any view is going to have to be revisionary to some extent, because our ordinary concept of belief is not ``coherent'' (142). His view is that, ``Our ordinary notion of belief both construes belief as a state of confidence short of certainty and takes consistency of belief to be something that is at least possible and, perhaps, even desirable'' and this is impossible. I think the view here interprets belief as a state less than confidence and allows for as much consistency as the folk view does (i.e. consistency amongst salient propositions), so this defence is unsuccessful as well.