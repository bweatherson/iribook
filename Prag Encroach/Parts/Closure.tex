The second problem concerns conjunction. It is also set out clearly by Stalnaker.

\begin{quote}
Reasoning in this way from accepted premises to their deductive consequences (\(P\), also \(Q\), therefore \(R\)) does seem perfectly straightforward. Someone may object to one of the premises, or to the validity of the argument, but one could not intelligibly agree that the premises are each acceptable and the argument valid, while objecting to the acceptability of the conclusion. \cite[92]{Stalnaker1984}
\end{quote}

\noindent If categorical belief is having a credence above the threshold, then one can coherently do exactly this. Let \(x\) be a number between \(r\) and than \(r\)\textsuperscript{ \(\nicefrac{1}{2}\)}, such that for an atom of type U has probability \(x\) of decaying within a time \(t\), for some \(t\) and U. Assume our agent knows this fact, and is faced with two (isolated) atoms of U. Let \(p\) be that the first decays within \(t\), and \(q\) be that the second decays within \(t\). She should, given her evidence, believe \(p\) to degree \(x, q\) to degree \(x\), and \(p \wedge q\) to degree \(x ^2\). If she believed \(p \wedge q\) to a degree greater than \(r\), she'd have to either have credences that were not supported by her evidence, or credences that were incoherent. (Or, most likely, both.) So the Threshold View violates the platitude. 

This is a well-known argument, so there are many responses to it. The best such response, I think, involves the preface paradox. David \cite{Christensen2005}, for example, argues that the preface paradox provides a reason for doubting that beliefs must be closed under entailment, or even must be consistent. Here is his description of the case.

\begin{quote}
We are to suppose that an apparently rational person has written a long non-fiction book---say, on history. The body of the book, as is typical, contains a large number of assertions. The author is highly confident in each of these assertions; moreover, she has no hesitation in making them unqualifiedly, and would describe herself (and be described by others) as believing each of the book's many claims. But she knows enough about the difficulties of historical scholarship to realize that it is almost inevitable that at least a few of the claims she makes in the book are mistaken. She modestly acknowledges this in her preface, by saying that she believes the book will be found to contain some errors, and she graciously invites those who discover the errors to set her straight. \citep[33-4]{Christensen2005}
\end{quote}

\noindent Christensen thinks such an author might be rational in every one of her beliefs, even though these are all inconsistent. Although he does not say this, nothing in his discussion suggests that he is using the irrelevance of some of the propositions in the author's defence. So here is an argument that we should abandon closure amongst relevant beliefs.\footnote{As we'll see in the next section, I'm going to agree that a rational agent can have inconsistent beliefs, provided not all of the beliefs in question are relevant to her current interests.}

Christensen's discussion, like many other discussions of the preface paradox, makes frequent use of the fact that examples like these are quite common. We don't have to go to fake barn country to find a counterexample to closure. But it seems to me that we need two quite strong idealisations in order to get a real counterexample here.

The first of these is discussed by Ishani \cite{MaitraANG}, and is briefly mentioned by Christensen in setting out the problem. We only have a counterexample to closure if the author \textit{believes} every thing she writes in her book. (Indeed, we only have a counterexample if she reasonably believes every one of them. But we'll assume a rational author who only believes what she ought to believe.) This seems unlikely to be true to me. An author of a historical book is like a detective who, when asked to put forward her best guess about what explains the evidence, says ``If I had to guess, I'd say {\dots}'' and then launches into spelling out her hypothesis. It seems clear that she need not \textit{believe} the truth of her hypothesis. If she did that, she could not later learn it was true, because you can't learn the truth of something you already believe. And she wouldn't put any effort into investigating alternative suspects. But she can come to learn her hypothesis was true, and it would be rational to investigate other suspects. It seems to me (following here Maitra's discussion) that we should understand scholarly assertions as being governed by the same kind of rules that govern detectives making the kind of speech being contemplated here. And those rules don't require that the speaker believe the things they say without qualification. The picture is that the little prelude the detective explicitly says is implicit in all scholarly work.

There are three objections I know to this picture, none of them particularly conclusive. First, Christensen says that the author doesn't qualify their assertions. But neither does our detective qualify most individual sentences. Second, Christensen says that most people would describe our author as believing her assertions. But it is also natural to describe our detective as believing the things she says in her speech. It's natural to say things like ``She thinks it was the butler, with the lead pipe,'' in reporting her hypothesis. Third, Timothy \cite{Williamson2000-WILKAI} has argued that if speakers don't believe what they say, we won't have an explanation of why Moore's paradoxical sentences, like ``The butler did it, but I don't believe the butler did it,'' are always defective. Whatever the explanation of the paradoxicality of these sentences might be, the alleged requirement that speakers believe what they say can't be it. For our detective cannot properly say ``The butler did it, but I don't believe the butler did it'' in setting out her hypothesis, even though \textit{believing} the butler did it is not necessary for her to say ``The butler did it'' in setting out just that hypothesis.\footnote{I'm assuming here that we should offer a quite different explanation of sentences like \textit{p but I don't believe it} and sentences like \textit{p but I don't know it}. I'll come back to the latter kind of sentence in later chapters. For the reasons given towards the end of \cite{MaitraWeatherson}, I don't think that kind of sentence has anything like the significance to the theory of assertion that it is frequently given.}

It is plausible that for \textit{some} kinds of books, the author should only say things they believe. This is probably true for travel guides, for example. Interestingly, casual observation suggests that authors of such books are much less likely to write modest prefaces.\footnote{Here's an example from Lonely Planet.\begin{quote}Things change -- prices go up, schedules change, good places go bad and bad places go bankrupt. Nothing stays the same. So, if you find things better or worse, recently opened or long-since closed, please tell us and help make the next edition even more accurate and useful.\end{quote} That doesn't quite \textit{say} that everything in the book when it is published, but it strongly implicates that discrepancies between the book and the world as you find it are due to a changing world, not inaccuracies in the book. It certainly isn't the modest preface beloved of fans of the preface paradox. \par I believe this kind of comment is standard in a range of Lonely Planet guides, but the particular quote I have here is from \citet[7]{FallonYale2000}, a book that I assume is now primarily useful for philosophical uses like this one.} This makes some sense if those books can only include statements their authors believe, and the authors believe the conjunctions of what they believe.

The second idealisation is stressed by Simon \citeauthor{Evnine1999} in his paper ``Believing Conjunctions''. The following situation does not involve me believing anything inconsistent. 

\begin{itemize*}
\item I believe that what Papi just said, whatever it was, is false. 
\item Papi just said that the stands at Fenway Park are green. 
\item I believe that the stands at Fenway Park are green. 
\end{itemize*}

\noindent If we read the first claim \textit{de dicto}, that I believe that Papi just said something false, then there is no inconsistency. (Unless I also believe that what Papi just said was that the stands in Fenway Park are green.) But if we read it \textit{de re}, that the thing Papi just said is one of the things I believe to be false, then the situation does involve me being inconsistent. The same is true when the author believes that one of the things she says in her book is mistaken. If we understand what she says \textit{de dicto}, there is no contradiction in her beliefs. It has to be understood \textit{de re} before we get a logical problem. And the fact is that most authors do not have \textit{de re} attitudes towards the claims made in their book. Most authors don't even remember everything that's in their books. (I'm not sure I remember how this section started, let alone this book.) Some may argue that authors don't even have the capacity to consider a proposition as long and complicated as the conjunction of all the claims in their book. Christensen considers this objection, but says it isn't a serious problem.

\begin{quote}
It is undoubtedly true that ordinary humans cannot entertain book-length conjunctions. But surely, agents who do not share this fairly \textit{superficial} limitation are easily conceived. And it seems just as wrong to say of such agents that they are rationally required to believe in the inerrancy of the books they write. (38: my emphasis)
\end{quote}

\noindent I'm not sure this is undoubtedly true; it isn't clear that propositions (as opposed to their representations) have lengths. And humans can believe propositions that \textit{can} be represented by sentences as long as books. But even without that point, Christensen is right that there is an idealisation here, since ordinary humans do not know exactly what is in a given book, and hence don't have \textit{de re} attitudes towards the propositions expressed in the book.

I'm actually rather suspicious of the intuition that Christensen is pushing here, that idealising in this way doesn't change intuitions about the case. The preface paradox gets a lot of its (apparent) force from intuitions about what attitude we should have towards real books. Once we make it clear that the real life cases are not relevant to the paradox, I find the intuitions become rather murky. But I won't press this point. 

A more important point is that we believers in closure don't think that authors should think their books are inerrant. Rather, we think that authors shouldn't unqualifiedly \textit{believe} the individual statements in their book if they don't believe the conjunction of those statements. Rather, their attitude towards those propositions (or at least some of them) should be that they are probably true.\footnote{The position I'm taking here is heavily influenced by the discussion in \citep{Stalnaker1984}, but I'm not sure whether it's the same in all details. In particular, I don't think it's particularly helpful to describe authors as `accepting' the propositions they put forward, as Stalnaker does. I'm not sure whether that's because I have a different take on the preface paradox to Stalnaker, or simply that we use `accept' to pick out slightly different states.} Proponents of the preface paradox know that this is a possible response, and tend to argue that it is impractical. Here is Christensen on this point.

\begin{quote}
It is clear that our everyday binary way of talking about beliefs has immense practical advantages over a system which insisted on some more fine-grained reporting of degrees of confidence {\dots} At a minimum, talking about people as believing, disbelieving, or withholding belief has at least as much point as do many of the imprecise ways we have of talking about things that can be described more precisely. (96)
\end{quote}

\noindent Richard Foley makes a similar point.

\begin{quote}
There are \textit{deep} reasons for wanting an epistemology of beliefs, reasons that epistemologies of degrees of belief by their very nature cannot possibly accommodate. \citep[170, my emphasis]{Foley1993}
\end{quote}

It's easy to make too much of this point. It's a lot easier to triage propositions into TRUE, FALSE and NOT SURE and work with those categories than it is to work assign precise numerical probabilities to each proposition. But these are not the only options. Foley's discussion subsequent to the above quote sometimes suggests they are, especially when he contrasts the triage with ``indicat[ing] as accurately as I can my degree of confidence in each assertion that I defend.'' (171) But really it isn't \textit{much} harder to add two more categories, PROBABLY TRUE and PROBABLY FALSE to those three, and work with that five-way division rather than a three-way division. It's not clear that humans as they are actually constructed have a \textit{strong} preference for the three-way over the five-way division, and even if they do, I'm not sure in what sense this is a `deep' fact about them.\footnote{A lot of recent work in experimental philosophy asks subjects to rank propositions on a seven-point scale, from clearly false to clearly true. That's exactly the kind of scale that I think humans easily and frequently construct for themselves. See, among many others, \cite{FeltzZarpentine2010}.}

Once we have the five-way division, it is clear what authors should do if they want to respect closure. For any conjunction that they don't believe (i.e. classify as true), they should not believe one of the conjuncts. But of course they can classify every conjunct as probably true, even if they think the conjunction is false, or even certainly false. Still, might it not be considered something of an idealisation to say rational authors must make this five-way distinction amongst propositions they consider? Yes, but it's no more of an idealisation than we need to set up the preface paradox in the first place. To use the preface paradox to find an example of someone who reasonably violates closure, we need to insist on the following three constraints.

\begin{enumerate*}
\renewcommand{\labelenumi}{\alph{enumi})}
\item They are part of a research community where only asserting propositions you believe is compatible with active scholarship;
\item They know exactly what is in their book, so they are able to believe that one of the propositions in the book is mistaken, where this is understood \textit{de re}; but
\item They are unable to effectively function if they have to effect a five-way, rather than a three-way, division amongst the propositions they consider.
\end{enumerate*}

\noindent Put more graphically, to motivate the preface paradox we have to think that our inability to have \textit{de re} thoughts about the contents of books is a ``superficial constraint'', but our preference for working with a three-way rather than a five-way division is a ``deep'' fact about our cognitive system. Maybe each of these attitudes could be plausible taken on its own (though I'm sceptical of that) but the conjunction seems just absurd.

I'm not entirely sure an agent subject to exactly these constraints is even fully conceivable. (Such an agent is negatively conceivable, in the terminology of \cite{Chalmers2002}, but I rather doubt they are positively conceivable.) But even if they are a genuine possibility, why the norms applicable to an agent satisfying that very gerrymandered set of constraints should be considered relevant norms for our state is far from clear. I'd go so far as to say it's clear that the applicability (or otherwise) of a given norm to such an odd agent is no reason whatsoever to say it applies to us. But since the preface paradox only provides a reason for just these kinds of agents to violate closure, we have no reason for ordinary humans to violate closure. So I see no reason here to say that we can have probabilistic coherence without logical coherence, as proponents of the threshold view insist we can have, but which I say we can't have \textit{at least when the propositions involved are salient}. The more pressing question, given the failure of the preface paradox argument, is why I don't endorse a much stronger closure principle, one that drops the restriction to salient propositions. The next section will discuss that point.

