## Theoretical Knowledge

Knowledge structures proper practical deliberation. And because what things can be taken as structural assumptions differs between different pieces of practical reasoning, knowledge is sensitive to the interests of the inquirer. But this isn't the only way in which knowledge is sensitive to interests. It is also sensitive to which purely theoretical questions the inquirer is taking an interest in.

I've already mentioned one way in which this has to be true. One kind of theoretical question is _What should I do in this kind of situation?_ And if actually being in that kind of situation and having to decide what to do affected what one knows, then thinking abstractly about it should affect what one knows as well.

This kind of comparison, between practical deliberation about what to do, and theoretical deliberation about what one should in just that situation, suggests a few things. It suggests that if practical interests affect knowledge, then so do theoretical interests. And it suggests that they should do so in more or less the same way. So it would be good to have a story that assigns to knowledge the role of structuring theoretical deliberation, in just the way that it structures practical deliberation. And that's more or less the story I'm going to tell, though there are some complications along the way.

The story I like starts with an observation by Pamela Hieronymi.

> A reason, I would insist, is an item in (actual or possible) reasoning. Reasoning is (actual or possible) thought directed at some question or conclusion. Thus, reasons must relate, in the first instance, not to states of mind but to questions or conclusions. [@Hieronymi2013, 115-6]

A first approximation is that the inquirer knows that $p$ only if they can properly use $p$ as a reason in "thought directed at the question" they are considering. That is, they can use $p$ as a step in this reasoning. This way of putting things connects Hieronymi's view of reasons to the idea present in both @HawthorneStanley2008 and @FantlMcGrath2009 that things known are reasons. And while I'm going to spend the rest of this section quibbling about whether this is quite right, it's an incredibly important first step.

It's enough to get us a fairly strong, but fairly natural, kind of interest-relativity. In normal circumstances, Anisa knows that the Battle of Agincourt was in 1415. Now imagine not that she's playing the red-blue game, but thinking about how to play it. And she wonders what to do if the red sentence says that two plus two is four, and the blue sentence says that the Battle of Agincourt was in 1415. It would be a mistake for her to reason as follows: Well, the Battle of Agincourt was in 1415, so playing Blue-True will get me $50, and nothing will get me more than $50, so I should play Blue-True. And it looks like the problem is the first step; she just can't take this for granted in this very context.

This is a very obscure kind of question to wonder about. But there are more natural questions that lead to the same kind of result. Imagine that the day after reading the book, Anisa starts wondering how likely it is that the book was correct. History books do make mistakes, and she wants to estimate how likely it is that this was a mistake. Again, it would be an error to reason as follows: Well, the Battle of Agincourt was in 1415, and that's what the book says, so the book is certainly correct. And it looks like the problem is the first step; she just can't take this for granted in this very context.

But it's not like she can only take for granted in that context things that are certain. If that were true, she couldn't even start inquiry into how likely it is the book got this wrong. She has to take a bunch of stuff as beyond the scope of present inquiry. She should not, as far as I can tell, question that the book says that the battle was in 1415, or that there was a Battle of Agincourt, or that it is  a fairly widely written about (but also fairly widely mythologised) battle, or that 1415 is before the invention of the printing press and this might affect the reliability of records, and so on. None of these things are things that she knows with Cartesian certainty. Indeed, some of them are probably all-things-considered less likely than that the Battle of Agincourt was in 1415. So it's not like there is some threshold of likelihood, or of evidential support, and inquiring into the likelihood of this statement implies that one can take for granted all and only things that clear this threshold. Rather, individual inquiries have their own logic, their own rules about what can be taken for granted.

There is an interesting analogy here with the rules of evidence in criminal trials. Whether some facts can be admitted at a trial depends in part on what the trial is. For example, some jurisidictions allow evidence obtained in a search that illegally violated X's rights to be used in a trial of Y, though it could not be used when X was on trial. The picture I have of knowledge is similar; what one knows is what one can use, and what one can use changes depending on the question under discussion.

So the starting point is that what's known is what can be used. But as it stands that's obviously too broad. If Anisa is currently inquiring into whether the local supermarket is open, she can't use as a reason that the Battle of Agincourt was in 1415. That's completely irrelevant. So we need, at the least, a relevancy exception to the rule that what is known is what can be used in reasoning. A better rule would say that the inquirer only knows that $p$ if $p$ can be used in reasoning unless it is irrelevant.

But even this might be too strong. There might be other rules that are like the relevance rule; rules that say why a fact can't be used as a reason without defeating the inquirer's claim to knowledge. Here are two possible such rules. (Note that I'm saying these are _possible_ rules; I take no stand on whether they really are constraints on inquiry.)

For one thing, there might be moral constraints on inquiry. This question is relevant to recent debates on whether there is 'moral encroachment' on knowledge, like I say there is pragmatic encroachment.^[Include citations here.] Perhaps, for instance, it is wrong to reason from the premises that $a$ is a member of group $G$, and most $G$s are $F$s, to the conclusion that $a$ is probably $F$. And this need not be because the premises are not known; rather, it is immoral to reason about people in this way. I'm a little sceptical of this kind of constraint. If there was a moral constraint on reasoning, I would have expected that it tracked the legal constraint on using premises that were obtained via violations of privacy. But there is no such constraint. Inferences from premises obtained via privacy violations can still produce knowledge; the immorality of the initial privacy violation does not undermine the epistemic standing of the conclusion. But all I want to note here is the possibility of such a constraint, and note that it raises problems for the idea that what is known is what can be used in reasoning.

Another source of trouble comes from holistic constraints on reasoning. What I have in mind here are rules that allow for a natural resolution of the puzzles of "transmission failure" that Crispin @Wright2002 discusses. Start with one of Wright's examples. Ada is walking by a park with a football pitch. It clearly isn't just a practice; the players are in uniforms and occupying familiar positions on the pitch, there is a referee and a crowd, and so on. One of the players kicks the ball into the net, the referee points to the centre of the ground, and half the players and crowd celebrate. And Ada reasons as follows.

1. The ball was kicked into the net, and no foul or violation was called.
2. So, a goal was scored.
3. So, a football match is being played, as opposed to, e.g., an ersatz match for the purposes of filming a movie.

As Wright points out, there is something wrong with the step from 2 to 3 here. And, as he also points out, it isn't trivial to say just what it is that's wrong. After all, 2 entails 3, and Ada knows that 2 entails 3. But it seems wrong to make just this _inference_.

Here's one way to identify what's wrong. It's surely too simple to be the full story, but it's a start. The transition Ada makes from 1 to 2 presupposes 3. And that's her only evidence for 2. When those two conditions are met, it is wrong to infer from 2 to 3. More generally, there is something wrong with inferring a conclusion from an intermediate step in reasoning if that conclusion must be presupposed in order to even reach that intermediate step.

This is too rough as it stands to be a full theory of what is going on in cases like Ada's. But the details aren't important here. (Though they will be in the next chapter.) What is important is that there might be some kind of holistic constraint on reasoning. In some sense, Ada goes wrong in taking 2 for granted when she infers 3. But this doesn't intuitively undermine her claim to know 2.

One important commonality between the last two cases, the moral encroachment and the transmission failure cases, is that the reasoning is not subject to the following kind of criticism. The speaker can't be criticised for taking as a premise something that might be false. Maybe there is something wrong with inferring something is probably true of an individual because it is true of most people in the group the individual is part of. But this restriction applies to the inference; not to the premises. We wouldn't say to the person who made this inference, "You shouldn't reason like that; it might not be true that most people in the group have this feature." If we did say that, they would have an easy reply. And if Ada does do the problematic reasoning, it would be wrong to reply to her "You shouldn't reason like this; it might not have been a goal." She could simply, and correctly, say that it quite clearly was a goal.

This is the key to the correct rule linking knowledge and reasoning. If the inquirer uses as a step in reasoning something that she knows to be true, then she is immune to a certain kind of criticism. She is immune to the criticism that the premise she used might not be true.

What I started this section doing was saying that such a reasoner is immune to all criticism, then trying to work out exceptions to that principle. So an exception needed to be included to allow that the reasoner might be criticised for using an irrelevant reason. And the hope was that eventually a full list of such exceptions could be found. But this project seems wildly optimistic. I don't know that we need to include further exceptions to handle the moral encroachment or transmission failure cases. But I also don't know that we don't need to include extra exceptions. And I have no idea, and no idea how to find out, whether we need yet more exceptions.

Rather than start with a universal claim of immunity and look for exceptions, a better way forward is to say that knowledge provides a certain kind of immunity. If the reasoner knows that the premise they use is true, they can't be criticised on the grounds that it might be false. This isn't a trivial claim. There were several examples involving Anisa where she could be criticised for using a premise that might be false. And all of those seemed like legitimate criticisms even though the premise was one she knew before starting the inquiry. But it says nothing about cases like the moral encroachment case, or the transmission failure case, or other cases like them that may be discovered.

* That's the principle: reasoning structured by knowledge is immune to this criticism.
* Flag that I'll say much more about this in chapter \@ref(evidence)
* And segue into talk about closure
