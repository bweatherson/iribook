## Intro

One simple way to motivate the idea that knowledge is sensitive to practical interests is to think about the role knowledge plays in action. Prima facie, the following two principles look fairly plausible.

Conditional Questions
:    If S knows that $p$, and the question _Q?_ is practically relevant, then S is entitled to answer the questions _Q?_, and _If p, Q?_ in the same way.

Possibility is a Defeater
:    If S should not take option X, and a reason S should not do this is because it might be that $\neg p$, then S does not know that $p$.

The first principle, **Conditional Questions**, is plausible because it seems like whatever we know should be usable in our deliberation. We should be able to take what we know for granted. Deliberation has to start somewhere, and starting with what one knows feels like a very safe place to start. There is something deeply weird, almost Moore paradoxical, about thinking to oneself, _p is true, but I won't use it in this deliberation because it might be false_. But if we take $p$ for granted, then answering the question _If p, Q?_ just is answering the question _Q?_. When I say the questions are answered the same way, I don't just mean here that they get the same answer. I also mean that how one gets to that answer is the same in each case. This will become relevant to a particular kind of puzzle at the very end of the paper.^[At a big picture level, the point of these last three sentences is to adopt a picture similar to that of @RossSchroeder2014, who say that pragmatic encroachment comes from norms about the appropriate starting point to deliberation, rather than that of @Weatherson2005, who says it comes from norms about the appropriate conclusions of deliberation.]

The second principle, **Possibility is a Defeater** is plausible because the most natural reading of the modal term 'might' here is epistemic. The fact that $p$ is metaphysically possible is not (normally) the kind of thing that provides a reason for action. I should buy insurance against getting in a car accident next year, because I might, for all I know, get in such an accident. Even if it was for sale, I shouldn't buy such insurance against being in an accident last year because it's not true that I might have been in an accident. I was there, and I was not in any accidents (luckily enough). Accidents last year and accidents next year are equally metaphysically possible, and equally logically possible, but they differ in their epistemic status. That's the kind of possibility that matters for deliberation. (Or so I say - as we'll see, many people reject this little bit of reasoning.)

The two principles aren't logically equivalent, but they are mutually reinforcing. If the reason to answer the question _Should I do X?_ negatively is that it might be that $\neg p$, then one is not entitled to answer the questions _Should I do X?_ and _If p, should I do X?_ the same way. Conversely, if the possibility that $\neg p$ is irrelevant to whether one should do X, then one is entitled to treat at least the questions _Should I do X?_ and _If p, should I do X?_ the same way.

Adopting either of these principles leads to practical interests having an impact in epistemology in a by now familiar way. Assume that S is offered a bet on whether $p$ is true. If S accepts the bet and $p$ is true, a small child somewhere will be given a moment of blissful joy, while if S accepts the bet and $p$ is false, the whole world will be cast into The Bad Place. Unless S is incredibly confident that $p$, then S is not entitled to take the bet. And S should not take the bet because $p$ might be false, and if it is false, a disaster to being all disasters will ensue.

If one wants to make knowledge insensitive to practical interests, such as one's interests in keeping humanity out of The Bad Place, there are only three options. One is the sceptical option that denies people know much of anything. Another is to say that for anything we currently know, we would be entitled to take such a bet. (Such a view might be supplemented by a suggestion that taking the bet, while rational, would violate some kind of secondary norm, as @Williamson2005 proposes.) And the third is to reject these two principles.

The last option has proven to be by far the most popular option in the recent literature. And a wide array of examples and arguments have been proposed to try to undermine the intuitive plausibility. It would be more than a paper to respond to all of these arguments. In particular, I'm not going to respond (at least in this paper) to arguments that start with well designed thought experiments, and go via an intuition that the protagonist of that thought experiment does know something, but should not rely on it in reasoning. (Jessica Brown (-@Brown2008, -@Brown2011) has two such examples that have been widely discussed and endorsed.) 

Instead, I'm going to focus on a more recent set of challenges to **Conditional Questions** that concern cases where someone has to choose between almost indiscriminable options. It has been argued that **Conditional Questions** issues implausible verdicts about knowledge in such cases [@McGrathKim2019], and that it ends up endorsing violations of closure [@Zweeber2017; @AndersonHawthorne2019]. I'm going to argue that these problems only arise if the person making the choices is a certain kind of utility maximiser. And the chooser should not be that kind of maximiser; they should be a satisficer. The person about whom the theory makes odd predictions is the kind of person who spends more time and effort searching out information that is relevant to a decision than that information is worth. Everyone has to say something odd about those folks, and the view that starts with **Conditional Questions** and **Possibility is a Defeater** says nothing weirder than anyone else says about them.

One need not endorse these principles in order to defend pragmatic encroachment. Indeed, @McGrathKim2019 explicitly appeal to these close calls, these choices between almost indiscriminable options, to motivate a distinct version of pragmatic encroachment. Their view starts with considerations about reasons, not with considerations about conditionals. So it would be misleading to identity the defence of **Conditional Questions** with pragmatic encroachment.^[That's not even account for the fact that some sceptics, and some knowledge first theorists, endorse **Conditional Questions** without endorsing pragmatic encroachment.] So I'll use the shorthand 'conditional pragmatic encroachment' for the conjunction of **Conditional Questions**, **Possibility is a Defeater**, and pragmatic encroachment. And the point of this paper is to defend conditional pragmatic encroachment from a specific set of challenges - those that arise from cases involving choices between similar options.

While conditional pragmatic encroachment is indeed a form of pragmatic encroachment, it doesn't make any particular appeal to 'stakes'. This notion plays a big role in, for example, the version of pragmatic encroachment that Jason @Stanley2005 defends. But **Conditional Questions** generates a version where practical factors can matter in medium stakes, and even low stakes, situations.^[This point has been made before, e.g., by @ArmourGarb2011, @Weatherson2012, and @Armendt2019.] I'll quickly do a medium stakes case first, but we'll see that the stakes can get much lower as we go along. 

Ken is doing a quiz for money. Each correct answer gets you $50. The first question is _In which month did Richard Nixon resign?_ Ken is pretty confident that the answer is _August, 1974_. He was born that month, so the date has stuck with him. But this quiz has a funny loophole - you are allowed to use Google before answering. So Ken's choices are (a) say _August 1974_, (b) check Google, then say what Google says, and (c) say something else. If you think, as I do, that option (b) is rationally required in Ken's case, then **Conditional Questions** implies that Ken does not know, right this second, which month Richard Nixon resigned. 

Now $50 isn't nothing, and if you lower the prize enough the intuition that Ken is rationally required to check gets weaker. But it isn't anything like 'high stakes' in Stanley's sense. It is perhaps more like medium stakes. The proponent of **Conditional Questions** says that whether you can know $p$ turns in part on whether you can rely on $p$. And whether you can rely on $p$ depends both on the costs of being wrong, which is roughly what people mean by stakes, and on the costs of checking before relying on it. When those costs go to zero, the stakes can also be very low, but still enough to affect knowledge.^[I don't mean this to be a careful account of what 'stakes'-talk amounts to. I'm convinced by @AndersonHawthorne2019b that it is very hard to say what stakes are. And that is one reason to prefer a version of pragmatic encroachment that doesn't rely on such a contested notion.]

Finally, I need to say something about what I'm taking a conditional question to be. It's a question where the antecedent is taken as given, taken as a fixed point, in answering the question. To see what this amounts to, it's helpful to think about questions involving epistemic modals.^[I'm here following very closely some points that Thony @Gillies2011 has made.] Imagine that the only two suspects are the butler and the gardener. And consider the question _If the gardener is innocent, must the butler be guilty?_. The answer to that is yes. But that's a little surprising, since it is clearly false that the butler must be guilty (we know he might be innocent), and possible that the gardener is innocent. The point is that how we understand epistemic modals changes when we take something for granted. And what goes for epistemic modals goes equally for epistemic probabilities, and for expected utilities. In the context of a conditional question, these become claims about conditional modality, and conditional utility. This somewhat technical point won't matter greatly here - in fact it will mostly be used in making the problems for conditional pragmatic encroachment more severe - but it is important to keep in mind in order to understand the theory.

## An Example

Let's start with an example from a great thinker. It will require a little exegesis, but that's not unusual when using classic texts.

| Well Frankie Lee and Judas Priest
| They were the best of friends
| So when Frankie Lee needed money one day
| Judas quickly pulled out a roll of tens
| And placed them on the footstool
| Just above the potted plain
| Saying "Take your pick, Frankie boy,
| My loss will be your gain."

On a common reading of this, Judas isn't just asking Frankie how much money he wants to take, but which invididual notes. Let's simplify, and say that it is common ground that Frankie should only take $10, so the choice Frankie has is which of the individual notes he will take. This will be enough to set up the puzzle.

Assume something else that isn't in the text, but which isn't an implausible addition to the story. The world Frankie and Judas live in is not completely free of counterfeit notes. And it would be bad for Frankie to take a counterfeit note. It won't matter just how common these notes are, or how bad it would be. But our puzzle will be most vivid if each of these are relatively small quantities. So there aren't that many counterfeit notes in circulation, and the (expected) disutility to Frankie of having one of them is not great. There is some chance that he will get in trouble, but the chance isn't high, and the trouble isn't any worse than he's suffered before. Still, other things exactly equal, Frankie would prefer a genuine note to a counterfeit one.

Now for some terminology to help us state the problem Frankie is in. Assume there are $k$ notes on the footstool. Call them $n_1, \dots, \n_k$. Let $c_i$ be the proposition that note $n_i$ is counterfeit, and its negation $g_i$ be that it is genuine. Let $g$, without a subscript, be the conjunction $g_1 \wedge \dots \wedge g_n$; i.e., the proposition that all the notes are genuine. Let $t_i$ be the act of taking note $n_i$. Let $U$ be Frankie's utility function, and $Cr$ his credence function.

In our first version of the example, we'll make two more assumptions. Apart from the issue of whether the note is real or counterfeit, Frankie is indifferent between the notes, so for some $h, l$, $U(t_i | g_i) = h$ and $U(t_i | c_i) = l$ for all $i$, with of course $h > l$. And Frankie thinks each of the banknotes is equally likely to be genuine, so for some $p$, $Cr(g_i) = p$ for all $i$. (And the probability of any of them being a counterfeit is independent of the probability of any of the others being counterfeit.)

That's enough to get us two puzzles for the conditional form of pragmatic encroachment theory. 

First, Frankie doesn't know of any note that it is genuine. As things stand, Frankie is indifferent between $t_i$ and $t_j$ for any $i, j$. But conditional on $g_i$, Frankie prefers $t_i$ to $t_j$. Right now, the expected utility of taking either $i$ or $j$ is $ph + (1-p)l$. If Frankie conditionalises on $g_i$, then the utility of $t_j$ doesn't change, but the utility of $t_i$ now becomes $h$, and that's higher than $ph + (1-p)l$. Since the conditional form of pragmatic encroachment theory says that knowledge is inconsistent with conditionalising on that 'knowledge' changing preferences over pragmatically salient options, and $t_i$ and $t_j$ are really salient to Frankie, it follows that he doesn't know $g_i$. And $i$ was arbitrary in this proof, so he doesn't know of any of the notes that they are genuine. That's not very intuitive, but worse is to follow.

Second, Frankie does know all the notes are genuine, although he doesn't know of any note that it is genuine. Conditional on $g$, Frankie's preferences are unchanged over pragmatically salient options. He used to be indifferent between the notes; after conditionalising he is still indifferent. And there is no other reason that he doesn't know that $g$. So he knows $g$; but doesn't know any of its constituent conjuncts. This is a very unappealing option.

Change the example a bit, so we can generate the third problem. Keep that the probabilities of each note being genuine are equal and independent. But assume that the notes are laid out in a line, and Frankie is at one end of that line. So to get a note that is further away from him, he has to reach further. And this has an ever so small disutility. Let $r_i$ be the disutility of reaching for note $i$. And assume this value increases as $i$ increases, but is always smaller than $(1-p)(h-l)$. That last quantity is important, because it is the difference between the utility of taking an arbitrary note (with no penalty for the cost of reaching for it), and the utility of taking a genuine banknote.

Now Frankie does know one more thing. He knows $g_1$. That's because as things stand, he prefers $t_1$ to the other options. Conditional on $g_i$ for any $i \geq 2$, he prefers $t_i$ to $t_1$. So conditionalising on $g_i$ changes Frankie's preferences, so he doesn't know $g_i$, at least for $i \geq 2$.

This third puzzle is striking for two reasons. One is that it involves a change of strict preferences. Unconditionally, Frankie strictly prefers $t_1$ to $t_i$; conditional on $g_i$ he strictly prefers $t_i$ to $t_1$. When I first saw these puzzles, I thought we could possibly get around them by restricting attention to cases where conditionalisation changes a strict preference. This example shows that won't work. And the other reason is that it hightens the implausibility of the sceptical result that Frankie doesn't know $g_i$. The pragmatic encroachment theorist is trying to solve some puzzles where everything one can say results in counterintuitive consequences. Maybe we could say that this is a surprising case where pragmatic factors, in this case Frankie's need to choose, changes what he knows. But saying that Frankie knows the note nearest to him is genuine, while he does not know that about any other note, feels distinctively bad.

So we have three puzzles to try to solve, if we want to defend the conditional version of pragmatic encroachment theory.

1. In the case where Frankie has no reason to choose one note rather than another, he doesn't know of any note that it is genuine. And this is surprisingly sceptical.
2. In the case where he has a weak reason to choose one note, he knows that note is genuine, but not the others. This retains the surprisingly sceptical consequence of the first puzzle, and adds a surprising asymmetry.
3. In both cases, there seems to be a really bad closure failure, with Frankie knowing that all the notes are genuine, but not knowing of all or most individual notes that they are genuine.

Before we leave Frankie for a while, let's note one variation on the case that somewhat helps the pragmatic encroachment theorist. Imagine that the country they are in has just reached the level of technological sophistication where it can produce plastic banknotes. And, as Frankie knows, no one in the country has yet figured out how to produce forgeries of plastic banknotes that are even remotely plausible. Finally, assume that one of the notes, lucky $n_8$, is one of the new plastic notes, while the others are the old paper notes. If Frankie cares about counterfeit avoidance at all, he should take $n_8$. And he should do so because it definitely isn't a counterfeit, while each of the others might be. So in that case, Frankie doesn't know that the other notes are genuine, while he does know that $n_8$ is genuine.

The verdicts that **Possibility is a Defeater**, and by extension **Conditional Questions** give about this case seem perfectly reasonable to me. At the very least, opponents of those views have to either say something implausible about what Frankie should rationally do, or say something Moore-paradoxical. For instance, they might say that Frankie shouldn't take $n_4$ because it might be fraudulent, although he knows it isn't fraudulent. 

Someone who thinks **Conditional Questions** is true should think that this is another case where practical interests affect knowledge, even though the stakes are reasonably low. But as I've noted before, that's a natural consequence of the view.

## Back to Earth

Intuitions about highly contrived cases are sometimes deprecated. Perhaps the contrivance doesn't reveal deep problems with a philosophical theory, but merely a quirk of our intuitions. I am not going to take a stand on any big questions about the epistemology of intuitions here. Rather, I'm going to note that cases with the same structure as the story of Frankie Lee and Judas Priest are incredibly common in the real world. Thinking about the real world examples can show us how pressing the problems are, and eventually show us a way out of those problems.

So let's leave Frankie for now, just above the potted plain, and think about a new character. We will call this one David, and he is buying a few groceries on the way home from work. In particular, he has to buy a can of chickpeas, a bottle of milk, and a carton of eggs. To make life easy, we'll assume each of these cost the same amount - $5.^[If that sounds implausible to you, make the can/bottle/carton a different size, or change the currency to some other dollars than the one you're instinctively using. But I think this examples works tolerably well when understand as involving, for example, East Carribean dollars.] None of these purchases is entirely risk free. Canned goods are pretty safe, but sometimes they go bad. Milk is normally removed from sale when it goes sour, but not always. And eggs can crack, either in transit or just on the shelf. In David's world, just like ours, each of these risks is greater than the one that came before.

David has a favorite brand of chickpeas, eggs, and milk. And he knows where in the store they are located. So his shopping is pretty easy. But it isn't completely straightforward. First he gets the chickpeas. And that's simple; he grabs the nearest can, and unless it is badly dented, or leaking, he puts in in his basket. Next he goes onto the milk. The milk bottles have sell-by dates printed in big letters on the front. And David checks that he isn't picking up one that is about to expire. His store has been known to have adjacent bottles of milk with sell-by dates 10 days apart, so it's worth checking. But as long as the date is far enough in the future, he takes it and moves on. Finally, he comes to the eggs. (Nothing so alike as eggs, he always thinks to himself.) Here he has to do a little more work. He takes the first carton, opens it to see there are no cracks on the top of the eggs, and, finding none, puts that in his basket too. He knows some of his friends do more than this; flipping the carton over to check for cracks underneath. But the one time he tried that, the eggs ended up on the floor. And he knows some of his friends do less; just picking up the carton by the underside, and only checking for cracks if the underside is sticky where the eggs have leaked. He thinks that makes sense too, but he is a little paranoid, and likes visual confirmation of what he's getting. All done, he heads to the checkout, pays his $15, and goes home.

The choice David faces when getting the chickpeas is like the choice Frankie faces. In a normal store, it will be more like the second version of the example than the first. After all, some of the cans will be towards the front, and others towards the back, and it will be easier to grab one of the ones from the front. That's why it is weird to get one from the back; it is incurring reaching costs without any particular payoff. But in all three cases, the choice David faces is something like the choice Frankie faced. He has to choose from among a bunch of very similar seeming options. In at least the chickpeas example, there is something you'd want to say that he knows: canned goods sold at reputable stores are safe. But the arguments above seem to show that David does not know this. Assuming there is some probability of the chickpeas not being safe, and the costs of reaching for some other can are low enough, David is in exactly the same situation as Frankie. Right now, he maximises utility by taking the front-most can. But conditional on one of the other cans being safe, he maximises utility by taking it. So he does not know of any of the other cans that they are safe.

Frankie's situation is weird. Who lays out some ten dollar bills and asks you to pick one? (Judas Priest, I guess.) But David's situation is not weird. Looking at a fully stocked shelf of industrially produced food, and needing to pick one can out of an array of similar items, is a very common experience. If a theory of knowledge yields bizarre verdicts about a case like this, it is no defence at all to say the situation is too obscure. In this modern world, it's an everyday occurrence.

## I Have Questions

So far I've assumed that these two questions are equivalent:

1. Which option has highest expected utility?
2. What to do?

In doing this, I've followed both critics of conditional pragmatic encroachment, but also some of its defenders. It is explicit in @Weatherson2005, for example, that practical questions are to be treated as questions about expected utility comparisons. But this equivalence is flawed for at least three reasons.

One is that it assumes away something that should not be assumed away. It simply assumes that risk-sensitive theories of choice, as defended by @Quiggin1983 and @Buchak2010, are mistaken. We probably shouldn't simply assume that, but the difference between expected utility theory and these alternatives isn't particularly relevant to Frankie's or David's choices, so I'll leave this aside for the rest of the paper.

A second is that someone might know all the relevant utility facts, and still not know what to do. When Frankie sits down, with his fingers to his chin, and tries to decide which of the tens to take, it's possible he knows that they each have the same utility. But he still has to pick one, and with his head spinning he can't decide which one to take. In cases like these answering questions about utility comparisons won't settle questions about what to do.^[James @Joyce2018 suggests the following terminology. If Frankie is rational, then utility considerations settle questions about what to _choose_, but not questions about what to _pick_ in the case of a tie. I haven't quite followed that terminology; I've let Frankie pick and choose more freely than that. But I'm following Joyce in stressing this conceptual distinction.]

I'm here disagreeing with @Stanley2011, who argues that questions involving bare infinitivals can always be paraphrased with questions involving modals. So he says that questions about what to do can be paraphrased as questions about what one should do. If this is a paraphrase, it is one that changes the meaning in exactly the cases that are interesting here. Frankie knows what he should do - pick an arbitrary banknote, it doesn't matter which one. But he doesn't know what to do. There isn't really a good way, in English at least, of restating what Frankie is ignorant about using modals. He knows the notes are basically the same, and he doesn't know which one to take.

The third way in which the equivalence is wrong takes a little longer to set up. The short version is that rational people are satisficers, and for a satisficer you can answer the question _What to do_ without taking a stand on questions about relative utility. The longer version is set out in the next section.

## You'll Never Be Satisfied (If You Try to Maximise)

The standard model of practical rationality that we use in philosophy is that of expected utility maximisation. But there are both theoretical and experimental reasons to think that this is not the right model for choices such as that faced by Frankie or David. Maximising expected utility is resource intensive, especially in contexts like a modern supermarket, and the returns on this resource expenditure are unimpressive. What people mostly do, and what they should do, is choose in a way that is sensitive to the costs of adopting one or other way.

There are two annoying terminological issues around here that I mostly want to set aside, but need to briefly address in order to forestall confusion. 

I'm going to assume maximising expected utility means maximising expected utility given facts that are readily available. So if one simply doesn't process a relevant but observationally obvious fact, that can lead to an irrational choice. I might alternatively have said that the choice was rational (given the facts the chooser was aware of), but the observational process was irrational. But I suspect that terminology would just add needless complication.

And I'm going to call any search procedure that is sensitive to resource considerations a satisficing procedure. This isn't uncommon in philosophical works, such as @XXX2017 and @YYY2017, but the standard usage in economics is considerably narrower. There the term 'satisficer' is restricted to agents who start a search with a 'reservation level' of quality, and choose when they find something meeting that level. So what @XXX2011 call a 'hybrid' search procedure, in contrast to a satisficing procedure, is what I'll call satisficing. But even there it is complicated. @YYY2011 have models that they call satisficing models where the reservation level is sensitive to the quality of goods already seen, and to the costs of search. And that ends up being not dissimilar to the hybrid models of @XXX2011. And it's those kinds of search procedures, ones which are satisficing models in the broader sense of being resource-sensitive, but not in the narrower sense of only aiming to clear a pre-established threshold, that I think rational agents adopt.

When David is facing the shelf of chickpeas, he can rationally take any one of them - apart perhaps from ones that are seriously damaged. How can the expected utility theory capture that fact? It says that more than one choice is permissible only if the choices are equal in expected utility. So the different cans are equal in expected utility. But on reflection, this is a wild claim. Some of the cans are ever so slightly easier to reach. Some of the cans will have ever so slight damage - a tiny dint here, a small tear in the label there - that just might indicate a more serious flaw. Of course, these small damages are almost always irrelevant, but as long as the probability that they indicate damage is positive, it breaks the equality of the expected utility of the cans. Even if there is no visible damage, some of the labels will be ever so slightly more faded, which indicates that the cans are older, which ever so slightly increases the probability that the goods will go bad before David gets to use them. Of course in reality this won't matter more than one time in a million, but one in a million chances matter if you are asking whether two expected utilities are strictly equal.

The common thread to the last paragraph is that these objects on the shelves are almost duplicates, but the most careful quality control doesn't produce consumer goods that are actual duplicates. This is particularly true in Frankie's choice situation. If all the notes he looks at are really duplicates, down to the serial numbers, he should run away. There are always some differences. It is unlikely that these differences make precisely zero difference to the expected utility of each choice. And even if they do, discovering that is hard work.

A better model of search and choice says that the chooser should at features of each choice such the cost of evaluating each choice for this feature and processing this information is less than the expected gain from including the feature in the search choice. Other features should be simply assumed to be equal and irrelevant to the search and choice. 

The costs of doing an expanded search are non-trivial, so this could rule out considering a lot of features. I don't know of any experimental work on this particular choice problem - choosing a token from an array of almost indiscriminable types. But experimental work on related choice situations seems to back up the kind of model I have in mind, such as @@@XXX2011 seems to back up the idea that subjects do not maximise, but rather choose in a resource sensitive way.

To be sure, many people do aim to do something like maximise expected utility. One of the interesting findings on the research on consumer choice is that there is a split between people who are more like satisficers in the economists' sense, and people who are more like maximisers. But the maximisers don't end up doing particularly well. They do badly at judging how long they are taking to make a decision, perhaps because they are not valuing time (@@@Citation). And they are somewhat less satisfied with the eventual decision, perhaps because they were attending to the costs of it so carefully (@@@Citation). 

The point here is not that empirical evidence confirms that people normally do what I'm recommending here and choose in a way that is sensitive to the resource costs of different choice procedures. Some people do, and the effect of averaging over a population including both satisficers and maximisers can often result in the average member of a population doing just what I'm recommending. Still, that doesn't show that it is the right thing to do. My argument here is that choosing in a way that is sensitive to the resource costs of using different choice procedures is theoretically very attractive, and the empirical evidence shows that it is both practical (some people do it) and useful (these people get pretty good results). So the empirical evidence at the very least doesn't undermine the intuitive, theoretical case, and may provide some extra support for it.

With that picture of resource-sensitive choice on the table, it's time to go back to David, staring at the cans of chickpeas, and Frankie, who has sat back down still thinking about what to do.

## Ignorance is Bliss

There are a lot of things that could have gone wrong with a can of chickpeas. They could have gone bad inside the can. They could have been contaminated, either deliberately or through carelessness. They could have been sitting around so long they have expired. All these things are, at least logically, possible.

But these possibilities, while serious, have two quite distinctive features. One is that they are very rare. In some cases they may have never happened. (I've never heard of someone deliberately contaminating canned chickpeas, though other grocery products have been contamination targets.) The other is that there are few easy ways to tell whether they are actualised. You can scan each of the cans for an expiry date, but it is really uncommon that this is relevant, and it takes work since the expiry dates are normally written in such small type. If a can is really badly dented, I guess that weakens the metal and raises ever so slightly the prospect of unintentional contamination. But it's common to have shelves full of cans that have no dents, or at most very minor ones. 

Given these two facts - the rarity of the problems and the difficulty in getting evidence that significantly shifts the probability that this is one of the (rare) problems - the rational thing to do is choose in a way that is insensitive to whether those problems are actualised. Or, perhaps more cautiously, one should be vigilant, in the sense of @SperberEtAl2011, to some of these problems, and ignore the rest. But being vigilant about a problem means, I take it, being willing to consider it if and only if you get evidence that it is worth considering. In the short run, you still ignore the potential problem.

And to ignore a potential problem is to choose in a way that is insensitive to evidence for the problem. That makes sense for both the banknotes and the chickpeas, because engaging in a choice procedure that is sensitive to the probability of the problem will, in the long run, make you worse off.

But if you're ignoring a potential problem, then conditionalising on the fact that it doesn't obtain won't change how you think. So for a person who chooses well, the puzzles don't get started. Conditionalising on this can of chickpeas isn't contaminated, or isn't about to expire, doesn't change anything. So even according to conditional pragmatic encroachment, it is known that each of the cans is fine, and the puzzles don't get off the ground.

There were two caveats in that last paragraph - I restricted attention to the chickpeas, and I restricted attention to people who choose well. We need to drop both of those restrictions to be sure that there aren't any counterexamples around here.

Extending the analysis to the other examples is reasonably easy though, and I'll run through them fairly quickly. 

David doesn't know that the eggs aren't cracked before he opens them up to check. If he did know they weren't cracked, it would have been a waste of effort to open the container. But it is not a waste of effort; he should check because they might be cracked. Via **Probability is a Defeater**, that implies he doesn't know they aren't cracked.

That isn't too surprising, but note that we can make the probability of eggs being cracked really low, and still have it be that he doesn't know. (Perhaps someone invents a new egg container that does a great job of crack preventing, so in David's world eggs are cracked only as often as canned goods are spoiled.) As long as there is a really low cost way to check whether the eggs are cracked, David should check. And since he should check because the eggs might be cracked, he doesn't know they aren't cracked.

This is another illustration of how conditional pragmatic encroachment really doesn't care about stakes. The stakes in this case are not zero - buying cracked eggs wastes money and that's why he should check. But they aren't 'high stakes' as that term has been used. And they aren't higher stakes than in the chickpeas example. What matters is not the cost of being wrong about an assumption, but rather the relative cost of being wrong compared to the probability that one is wrong and the cost of checking.

So when buying the eggs, David doesn't know of each egg carton that it contains intact eggs. But one of the objections we started with said that he might still know that they all contain uncracked eggs, especially in the world where egg-cracking is less common than in the actual world. But in that world, conditionalising on the hypothesis that all the eggs are uncracked will change David's behaviour. He will just pick up the first carton and put it in his shopping basket, rather than check for whether the eggs in it are cracked. So, by **Conditional Questions** he also doesn't know that all the eggs are uncracked, and there isn't a closure violation.

The milk case is only slightly more complicated. At least in some places, the expiry date for milk is written in very large print on the front of the bottle. In those cases, it is worth checking that you aren't buying milk that expires tomorrow. So before you check, you don't know that the milk you pick up doesn't expire tomorrow. (And, like in the eggs case, that's true even if the shop very very rarely sells milk that close to the expiry date.) But there is no way to check whether a particular unexpired milk has gone bad. You can't easily open a milk bottle in the supermarket and smell it, for example. So that's the kind of rare and uncheckable problem that the sensible chooser will ignore. And ignored problems, as we've already seen, don't raise difficulties for conditional pragmatic encroachment.

So none of the cases raise problems if the person making the choice is choosing in the right way. In some cases they do know, of each item, that it doesn't manifest the rare problem. And they know this because they can and do rationally ignore the potential problem. In other cases they can't ignore this problem, so they don't know the problem isn't real, but that's both independently plausible, and doesn't lead to closure violations. ^[Note here that 'independently plausible' doesn't mean conditional pragmatic encroachment intuitively gets the right answer; it just means that we can tell a plausible story that motivates that answer. I'm not reasoning from the claims conditional pragmatic encroachment makes about what is known in these cases to the truth of the theory.]

I said a little while ago that there were two problems - how to handle the other cases, and how to handle people who don't make choices in the right way. The latter problem is a little harder, and we'll end with it.

## What does the Maximiser Know about Choosing?


