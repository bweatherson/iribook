### Probability and Arbitrariness {#arbitrary}

The Lockean says that there is some number $r$ such that a person believes that $p$ iff their credence in $p$ is at least $r$. As Robert Stalnaker [-@Stalnaker1984 91] emphasised, any number $r$ is bound to seem arbitrary. Unless these numbers are made salient by the environment, there is no special difference between believing $p$ to degree 0.9786 and believing it to degree 0.9875. But if $r$ is 0.98755, this will be the difference between believing $p$ and not believing it, which is an important difference. 

One response to this, often traced back to these provocative remarks by Richard Jeffrey, is to deny that the difference between believing and not believing is important.

> Nor am I disturbed by the fact that our ordinary notion of belief is only vestigially present in the notion of degree of belief. I am inclined to think Ramsey sucked the marrow out of the ordinary notion, and used it to nourish a more adequate view. [@Jeffrey1970 171-2]

Put less provocatively, Jeffrey's remarks here suggest the view that the relationship between belief and degree of belief is like the relationship between being tall and height. There are tall people, and being tall is even sometimes important. All star basketball players are tall, while no star gymnasts are. But the really important notion is height; being tall or otherwise doesn't add anything of theoretical significance.

But we can see from the discussion in section \@ref(agency) that this can't be right. There are important generalisations about belief that can't be stated just using degrees of belief.

Another response to the arbitrariness worry, as found in @Foley1993 [ch. 4] and @Hunter1996 is to say that the value $r$ is vague. But it's not clear how this helps. On an epistemic theory of vagueness, there is still a number such that degrees of belief above that count, and degrees below that do not, and any such number is bound to seem unimportant. On supervaluational  theories, the same is true. There won't be a determinate number, to be sure, but there will a number, and that seems false. The comparative truth theory of vagueness that I've previously defended [@Weatherson2005-WEATTT] has the same consequence. Hunter defends a version of the threshold view combined with a theory of vagueness based around fuzzy logic, which in principle could solve the arbitrariness problem. But adjusting logic to defend a theory of belief seems way over the top, especially when, as @Williamson1994-WILV has argued, there are serious problems with the proposed adjustment.
