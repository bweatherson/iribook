A better move is to start with the functionalist idea that to believe that $p$ is to treat $p$ as true for the purposes of practical reasoning. To believe $p$ is to have preferences that make sense, by your own lights, in a world where $p$ is true. So, if you prefer A to B and believe that $p$, you prefer A to B given $p$. For reasons that will become apparent below, we'll work in this paper with a notion of preference where \textit{conditional} preferences are primary.\footnote{To say the agent prefers A to B given $q$ is not to say that if the agent were to learn $q$, she would prefer A to B. It's rather to say that she prefers the state of the world where she does A and $q$ is true to the state of the world where she does B and $q$ is true. These two will come apart in cases where learning $q$ changes the agent's preferences. We'll return to this issue below.} So the core insight we'll work with is the following:

\begin{quote}
If you prefer A to B given $q$, and you believe that $p$, then you prefer A to B given $p \wedge q$
\end{quote}

\noindent The bold suggestion here is that if that is true for all the A, B and \textit{q }that matter, then you believe $p$. Put formally, where \textit{Bel}($p$) means that the agent believes that $p$, and A $\geq _q$ B means that the agent thinks A is at least as good as B given $q$, we have the following

\begin{enumerate*}
\item \textit{Bel}($p$) $\leftrightarrow \forall$A$\forall$B$\forall q$ (A $\geq _q$ B $\leftrightarrow$ A $\geq _{p \wedge q}$ B)
\end{enumerate*}

\noindent In words, an agent believes that $p$ iff conditionalising on $p$ doesn't change any conditional preferences over things that matter.\footnote{This might seem \textit{much} too simple, especially when compared to all the bells and whistles that functionalists usually put in their theories to (further) distinguish themselves from crude versions of behaviourism. The reason we don't need to include those complications here is that they will all be included in the analysis of \textit{preference}. Indeed, the theory here is compatible with a thoroughly anti\nobreakdash-functionalist treatment of preference. The claim is not that we can offer a functional analysis of belief in terms of non-mental concepts, just that we can offer a functionalist reduction of belief to other mental concepts. The threshold view is \textit{also} such a reduction, but it is such a crude reduction that it doesn't obviously fall into any category.} The left-to-right direction of this seems trivial, and the right\nobreakdash-to\nobreakdash-left direction seems to be a plausible way to operationalise the functionalist insight that belief is a functional state. There is some work to be done if (1) is to be interpreted as a truth though.

If we interpret the quantifiers in (1) as unrestricted, then we get the (false) conclusion that just about no one believes no contingent propositions. To prove this, consider a bet that wins iff the statue in front of me waves back at me due to random quantum effects when I wave at it. If I take the bet and win, I get to live forever in paradise. If I take the bet and lose, I lose a penny. Letting A be that I take the bet, B be that I decline the bet, $q$ be a known tautology (so my preferences given $q$ are my preferences \textit{tout court}) and $p$ be that the statue does not wave back, we have that I prefer A to B, but not A to B given $p$. So by this standard I don't believe that $p$. This is false -- right now I believe that statues won't wave back at me when I wave at them.

This seems like a problem. But the solution to it is not to give up on functionalism, but to insist on its pragmatic foundations. The quantifiers in (1) should be restricted, with the restrictions motivated pragmatically. What is crucial to the theory is to say what the restrictions on A and B are, and what the restrictions on $q$ are. We'll deal with these in order.

For better or worse, I don't right now have the option taking that bet and hence spending eternity in paradise if the statue waves back at me. Taking or declining such unavailable bets are not open choices. For any option that is open to me, assuming that statues do not in fact wave does not change its utility. That's to say, I've already factored in the non-waving behaviour of statues into my decision-making calculus. That's to say, I believe statues don't wave.

An action A is a live option for the agent if it is really possible for the agent to perform A. An action A is a salient option if it is an option the agent takes seriously in deliberation. Most of the time gambling large sums of money on internet gambling sites over my phone is a live option, but not a salient option. I know this option is suboptimal, and I don't have to recompute every time whether I should do it. Whenever I'm making a decision, I don't have to add in to the list of choices \textit{bet thousands of dollars on internet gambling sites}, and then rerule that out every time. I just don't consider that option, and properly so. If I have a propensity to daydream, then becoming the centrefielder for the Boston Red Sox might be a salient option to me, but it certainly isn't a live option. We'll say the two initial quantifiers range over the options that are live and salient options for the agent. 

Note that we \textit{don't} say that the quantifiers range over the options that are live and salient for the person making the belief ascription. That would lead us to a form of contextualism for which we have little evidence. We also don't say that an option becomes salient for the agent iff they \textit{should} be considering it. At this stage we are just saying what the agent does believe, not what they should believe, so we don't have any clauses involving normative concepts.

Now we'll look at the restrictions on the quantifier over propositions. Say a proposition is \textit{relevant} if the agent is disposed to take seriously the question of whether it is true (whether or not she is currently considering that question) and conditionalising on that proposition or its negation changes some of the agents \textit{unconditional} preferences over live, salient options.\footnote{Conditionalising on the proposition \textit{There are space aliens about to come down and kill all the people writing epistemology papers} will make me prefer to stop writing this paper, and perhaps grab some old metaphysics papers I could be working on. So that proposition satisfies the second clause of the definition of relevance. But it clearly doesn't satisfy the first clause. This part of the definition of relevance won't do much work until the discussion of agents with mistaken environmental beliefs in section 7.} The first clause is designed to rule out wild hypotheses that the agent does not take at all seriously. If $q$ is not such a proposition, if the agent is disposed to take it seriously, then it is relevant if there are live, salient A and B such that A $\geq _q$ B $\leftrightarrow$ A $\geq$ B is false. Say a proposition is \textit{salient} if the agent is currently considering whether it is true. Finally, say a proposition is \textit{active} relative to $p$ iff it is a (possibly degenerate) conjunction of propositions such that each conjunct is either relevant or salient, and such that the conjunction is consistent with $p$. (By a degenerate conjunction I mean a conjunction with just one conjunct. The consistency requirement is there because it might be hard in some cases to make sense of preferences given inconsistencies.) Then the propositional quantifier in (1) ranges over active propositions.

We will expand and clarify this in the next section, but our current solution to the relationship between beliefs and degrees of belief is that degrees of belief determine an agent's preferences, and she believes that $p$ iff the claim (1) about her preferences is true when the quantifiers over options are restricted to live, salient actions, and the quantifier over propositions is restricted to salient propositions. The simple view would be to say that the agent believes that $p$ iff conditioning on $p$ changes none of her preferences. The more complicated view here is that the agent believes that $p$ iff conditioning on $p$ changes none of her conditional preferences over live, salient options, where the conditions are also active relative to $p$.
