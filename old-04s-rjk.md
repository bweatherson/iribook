## Rationality, Justification and Knowledge {#rjk}

Fantl and McGrath argue for the principle (JJ), which entails that Coraline is not justified in believing $p$.

(JJ)    If you are justified in believing that $p$, then $p$ is warranted enough to justify you in $\varphi$-ing, for any $\varphi$. [@FantlMcGrath2009 99]

In practice, what this means is that there can't be a salient $p, \varphi$ such that:

* The agent is justified in believing $p$;
* The agent is not warranted in doing $\varphi$; but
* If the agent had more evidence for $p$, and nothing else, the agent would be be warranted in doing $\varphi$.

That is, once you've got enough evidence, or warrant, for justified belief in $p$, then you've got enough evidence for $p$ as matters for
any decision you face. This seems intuitive, and Fantl and McGrath back up its intuitiveness with some nicely drawn examples. 

I used to think that Coraline was a counterexample to (JJ), but now I'm less sure. That's because, as I've noted in section (include cross-ref here), I no longer think it's very clear what to think about justified belief. But there is a principle very similar to (JJ) that I am committed to denying. 

(RR) If you are rational in believing that $p$, then $p$ is warranted enough to rationalise you in $\varphi$-ing, for any $\varphi$. 

But I think it is
false, and the Coraline example shows it is false. Coraline isn't justified in taking the bet, and is justified in believing $p$, but more evidence for $p$ would suffice for taking the bet. So Coraline's case shows that (JJ) is false. But there are a number of possible objections to that position. I'll spend the rest of this section, and this paper,
going over them.

^[Cut all of the rest of this. First, note the move from JJ to RR. Then note Coraline is a counterexample to RR. Then include the paragraph about holistic identification and atomic evaluation.  Then have a counterargument: p, if p best to take bet, so best to take bet, so should take bet. Argue that this argument fails because it confuses conditional attitudes with attitudes to a conditional. In a Jackson case, if you have every one of the conditionals "If X, best to take bet" and have best > should conditional, then get the disjunction that should take one of the bad choices. And that disjunction is false. So the argument fails, Coraline is a counterexample to RR. And that means that not all interest relativity of knowledge is interest relativity of belief.]

^[Stepping back a bit, there's a reason the interest-relative theory says
that the ideal and justification come apart right here. On the
interest-relative theory, like on any pragmatic theory of mental states,
the *identification* of mental states is a somewhat holistic matter.
Something is a belief in virtue of its position in a much broader
network. But the *evaluation* of belief is (relatively) atomistic.
That's why Coraline is justified in believing $p$, although if she were
wiser she would not believe it. If she were wiser, i.e., if she had the
right attitude towards $q$, the very same credence in $p$ would not
count as a belief. Whether her state counts as a belief, that is,
depends on wide-ranging features of her cognitive system. But whether
the state is justified depends on more local factors, and in local
respects she is doing everything right.]


*Objection*: The following argument shows that Coraline is not in fact justified in believing that $p$.

1. $p$ entails that Coraline should take the bet, and Coraline knows this.
2. If $p$ entails something, and Coraline knows this, and she justifiably believes $p$, she is in a position to justifiably believe the thing entailed.
3. Coraline is not in a position to justifiably believe that she should take the bet.
C. So, Coraline does not justifiably believe that $p$

*Reply*: The problem here is that premise 1 is false. What's true is that $p$ entails that Coraline will be better off taking the bet than declining it. But it doesn't follow that she should take the bet.
Indeed, it isn't actually true that she should take the bet, even though $p$ is actually true. Not just is the entailment claim false, the world of the example is a counterinstance to it.

It might be controversial to use this very case to reject premise 1. But the falsity of premise 1 should be clear on independent grounds. What
$p$ entails is that Coraline will be best off by taking the bet. But there are lots of things that will make me better off that I shouldn't
do. Imagine I'm standing by a roulette wheel, and the thing that will make me best off is betting heavily on the number than will actually
come up. It doesn't follow that I should do that. Indeed, I should not do it. I shouldn't place any bets at all, since all the bets have a highly negative expected return.

In short, all $p$ entails is that taking the bet will have the best consequences. Only a very crude kind of consequentialism would identify what I should do with what will have the best returns, and that crude consequentialism isn't true. So $p$ doesn't entail that Coraline should take the bet. So premise 1 is false.

*Objection*: Even though $p$ doesn't *entail* that Coraline should take the bet, it does provide inductive support for her taking the bet. So if
she could justifiably believe $p$, she could justifiably (but non-deductively) infer that she should take the bet. Since she can't justifiably infer that, she isn't justified in taking the bet.

*Reply*: The inductive inference here looks weak. One way to make the inductive inference work would be to deduce from $p$ that taking the bet will have the best outcomes, and infer from that that the bet should be taken. But the last step doesn't even look like a reliable ampliative inference. The usual situation is that the best outcome comes from taking an *ex ante* unjustifiable risk.

It may seem better to use $p$ combined with the fact that conditional on $p$, taking the bet has the highest *expected* utility. But actually that's still not much of a reason to take the bet. Think again about cases, completely normal cases, where the action with the best outcome is an *ex ante* unjustifiable risk. Call that action $\varphi$, and let $B \varphi$ be the proposition that $\varphi$ has the best outcome. Then $B \varphi$ is true, and conditional on $B \varphi$, $\varphi$ has an
excellent expected return. But doing $\varphi$ is still running a dumb risk. Since these kinds of cases are normal, it seems it will very often be the case that this form of inference leads from truth to falsity. So it's not a reliable inductive inference.

*Objection*: In the example, Coraline isn't just in a position to
justifiably believe $p$, she is in a position to *know* that she
justifiably believes it. And from the fact that she justifiably believes
$p$, and the fact that if $p$, then taking the bet has the best option,
she can infer that she should take the bet.

*Reply*: It's possible at this point that we get to a dialectical
impasse. I think this inference is non-deductive, because I think the
example we're discussing here is one where the premises are true and the
conclusion false. Presumably someone who doesn't like the example will
think that it is a good deductive inference.

Having said that, the more complicated example at the end of
[@Weatherson2005-WEACWD] was designed to raise the same problem without
the consequence that if $p$ is true, the bet is sure to return a
positive amount. In that example, conditionalising on $p$ means the bet
has a positive expected return, but still possibly a negative return.
But in that case (JJ) still failed. If accepting there are cases where
an agent justifiably believes $p$, and hence justifiably believes taking
the bet will return the best outcome, and knows all this, but still
can't rationally bet on $p$ is too much to accept, that more complicated
example might be more persuasive. Otherwise, I concede that someone who
believes (JJ) and thinks rational agents can use it in their reasoning
will not think that a particular case is a counterexample to (JJ).

*Objection*:If Coraline were ideal, then she wouldn't believe $p$.
That's because if she were ideal, she would have a lower credence in
$q$, and if that were the case, her credence in $p$ would have to be
much higher (close to 0.999) in order to count as a belief. So her
belief is not justified.

*Reply*: The premise here, that if Coraline were ideal she would not
believe that $p$, is true. The conclusion, that she is not justified in
believing $p$, does not follow. It's always a mistake to *identify* what
should be done with what is done in ideal circumstances. This is
something that has long been known in economics. The *locus classicus*
of the view that this is a mistake is [@LipseyLancaster]. A similar
point has been made in ethics in papers such as [@Watson1977] and
[@KennettSmith1996b; @KennettSmith1996a]. And it has been extended to
epistemology by [@Williamson1998-WILCOK].

All of these discussions have a common structure. It is first observed
that the ideal is both $F$ and $G$. It is then stipulated that whatever
happens, the thing being created (either a social system, an action, or
a cognitive state) will not be $F$. It is then argued that given the
stipulation, the thing being created should not be $G$. That is not just
the claim that we shouldn't *aim* to make the thing be $G$. It is,
rather, that in many cases being $G$ is not the best way to be, given
that $F$-ness will not be achieved. Lipsey and Lancaster argue that (in
an admittedly idealised model) that it is actually quite unusual for $G$
to be best given that the system being created will not be $F$.

It's not too hard to come up with examples that fit this structure.
Following [@Williamson2000-WILKAI 209], we might note that I'm justified
in believing that there are no ideal cognitive agents, although were I
ideal I would not believe this. Or imagine a student taking a ten
question mathematics exam who has no idea how to answer the last
question. She knows an ideal student would correctly answer an even
number of questions, but that's no reason for her to throw out her good
answer to question nine. In general, once we have stipulated one
departure from the ideal, there's no reason to assign any positive
status to other similarities to the idea. In particular, given that
Coraline has an irrational view towards $q$, she won't perfectly match
up with the ideal, so there's no reason it's good to agree with the
ideal in other respects, such as not believing $p$.

Stepping back a bit, there's a reason the interest-relative theory says
that the ideal and justification come apart right here. On the
interest-relative theory, like on any pragmatic theory of mental states,
the *identification* of mental states is a somewhat holistic matter.
Something is a belief in virtue of its position in a much broader
network. But the *evaluation* of belief is (relatively) atomistic.
That's why Coraline is justified in believing $p$, although if she were
wiser she would not believe it. If she were wiser, i.e., if she had the
right attitude towards $q$, the very same credence in $p$ would not
count as a belief. Whether her state counts as a belief, that is,
depends on wide-ranging features of her cognitive system. But whether
the state is justified depends on more local factors, and in local
respects she is doing everything right.

*Objection*: If Coraline is justified in believing $p$, then Coraline
can use $p$ as a premise in practical reasoning. If Coraline can use $p$
as a premise in practical reasoning, and $p$ is true, and her belief in
$p$ is not Gettiered, then she knows $p$. By hypothesis, her belief is
true, and her belief is not Gettiered. So she should know $p$. But she
doesn't know $p$. So by several steps of modus tollens, she isn't
justified in believing $p$.[^29]

*Reply*: This objection this one turns on an equivocation over the
neologism 'Gettiered'. Some epistemologists use this to simply mean that
a belief is justified and true without constituting knowledge. By that
standard, the third sentence is false. Or, at least, we haven't been
given any reason to think that it is true. Given everything else that's
said, the third sentence is a raw assertion that Coraline knows that
$p$, and I don't think we should accept that.

The other way epistemologists sometimes use the term is to pick out
justified true beliefs that fail to be knowledge for the reasons that
the beliefs in the original examples from [@Gettier1963] fail to be
knowledge. That is, it picks out a property that beliefs have when they
are derived from a false lemma, or whatever similar property is held to
be doing the work in the original Gettier examples. Now on this reading,
Coraline's belief that $p$ is not Gettiered. But it doesn't follow that
it is known. There's no reason, once we've given up on the JTB theory of
knowledge, to think that whatever goes wrong in Gettier's examples is
the *only* way for a justified true belief to fall short of knowledge.
It could be that there's a practical defeater, as in this case. So the
second sentence of the objection is false, and the objection again
fails.

Once we have an expansive theory of defeaters, as I've adopted here, it
becomes problematic to describe the case in the language Fantl and
McGrath use. They focus a lot on whether agents like Coraline have
'knowledge-level justification' for $p$, which is defined as
"justification strong enough so that shortcomings in your strength of
justification stand in the way of your knowing". [@FantlMcGrath2009 97].
An important part of their argument is that an agent is justified in
believing $p$ iff they have knowledge-level justification for $p$. I
haven't addressed this argument, so I'm not really addressing the case
on their terms.

Well, does Coraline have knowledge-level justification for $p$? I'm not
sure, because I'm not sure I grasp this concept. Compare the agent in
Harman's dead dictator case [@Harman1973 75]. Does she have
knowledge-level justification that the dictator is dead? In one sense
yes; it is the existence of misleading news sources that stops her
knowing. In another sense no; she doesn't know, but if she had better
evidence (e.g., seeing the death happen) she would know. I want to say
the same thing about Coraline, and that makes it hard to translate the
Coraline case into Fantl and McGrath's terminology.
